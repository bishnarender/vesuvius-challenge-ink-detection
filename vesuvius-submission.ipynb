{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b61120e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T05:15:46.630654Z",
     "iopub.status.busy": "2023-08-12T05:15:46.630240Z",
     "iopub.status.idle": "2023-08-12T05:15:46.635787Z",
     "shell.execute_reply": "2023-08-12T05:15:46.634772Z"
    },
    "papermill": {
     "duration": 0.020234,
     "end_time": "2023-08-12T05:15:46.640354",
     "exception": false,
     "start_time": "2023-08-12T05:15:46.620120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This file is a modified version of the original:\n",
    "# https://www.kaggle.com/code/mipypf/ink-segmentation-2-5d-3dcnn-resnet3dcsn-fp16fold01/notebook?scriptVersionId=132226669"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c2a4b1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T05:15:46.655965Z",
     "iopub.status.busy": "2023-08-12T05:15:46.655412Z",
     "iopub.status.idle": "2023-08-12T05:15:54.184528Z",
     "shell.execute_reply": "2023-08-12T05:15:54.182799Z"
    },
    "papermill": {
     "duration": 7.540557,
     "end_time": "2023-08-12T05:15:54.188059",
     "exception": false,
     "start_time": "2023-08-12T05:15:46.647502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: timm 0.6.12\r\n",
      "Uninstalling timm-0.6.12:\r\n",
      "  Successfully uninstalled timm-0.6.12\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m0.9.5\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y timm\n",
    "import sys\n",
    "sys.path.append(\"/kaggle/input/timmmaster/\")\n",
    "import timm\n",
    "print(timm.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea323c56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T05:15:54.205857Z",
     "iopub.status.busy": "2023-08-12T05:15:54.204987Z",
     "iopub.status.idle": "2023-08-12T05:19:17.322381Z",
     "shell.execute_reply": "2023-08-12T05:19:17.321087Z"
    },
    "papermill": {
     "duration": 203.128966,
     "end_time": "2023-08-12T05:19:17.325182",
     "exception": false,
     "start_time": "2023-08-12T05:15:54.196216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/mmdetection-offline-lib/mmcv_full-1.3.14-cp37-cp37m-linux_x86_64.whl\r\n",
      "Installing collected packages: mmcv-full\r\n",
      "Successfully installed mmcv-full-1.3.14\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing /kaggle/input/mmdetection-offline-lib/pycocotools-2.0.2-cp37-cp37m-linux_x86_64.whl\r\n",
      "Installing collected packages: pycocotools\r\n",
      "Successfully installed pycocotools-2.0.2\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing /kaggle/input/mmdetection-offline-lib/terminaltables-3.1.0-py3-none-any.whl\r\n",
      "Installing collected packages: terminaltables\r\n",
      "Successfully installed terminaltables-3.1.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing /kaggle/input/mmdetection-offline-lib/pytest_runner-5.3.1-py3-none-any.whl\r\n",
      "Installing collected packages: pytest-runner\r\n",
      "Successfully installed pytest-runner-5.3.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing /kaggle/input/mmdetection-offline-lib/mmpycocotools-12.0.3-cp37-cp37m-linux_x86_64.whl\r\n",
      "Installing collected packages: mmpycocotools\r\n",
      "Successfully installed mmpycocotools-12.0.3\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing /kaggle/input/mmdetection-offline-lib/terminal-0.4.0-py3-none-any.whl\r\n",
      "Installing collected packages: terminal\r\n",
      "Successfully installed terminal-0.4.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing /kaggle/input/mmdetection-offline-lib/mmdet-2.17.0-py3-none-any.whl\r\n",
      "Installing collected packages: mmdet\r\n",
      "Successfully installed mmdet-2.17.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing /kaggle/input/mmdetection-offline-lib/addict-2.4.0-py3-none-any.whl\r\n",
      "Installing collected packages: addict\r\n",
      "Successfully installed addict-2.4.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing /kaggle/input/mmdetection-offline-lib/yapf-0.31.0-py2.py3-none-any.whl\r\n",
      "Installing collected packages: yapf\r\n",
      "  Attempting uninstall: yapf\r\n",
      "    Found existing installation: yapf 0.32.0\r\n",
      "    Uninstalling yapf-0.32.0:\r\n",
      "      Successfully uninstalled yapf-0.32.0\r\n",
      "Successfully installed yapf-0.31.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install /kaggle/input/mmdetection-offline-lib/mmcv_full-1.3.14-cp37-cp37m-linux_x86_64.whl --no-deps\n",
    "!pip install /kaggle/input/mmdetection-offline-lib/pycocotools-2.0.2-cp37-cp37m-linux_x86_64.whl --no-deps\n",
    "!pip install /kaggle/input/mmdetection-offline-lib/terminaltables-3.1.0-py3-none-any.whl --no-deps\n",
    "!pip install /kaggle/input/mmdetection-offline-lib/pytest_runner-5.3.1-py3-none-any.whl --no-deps\n",
    "!pip install /kaggle/input/mmdetection-offline-lib/mmpycocotools-12.0.3-cp37-cp37m-linux_x86_64.whl --no-deps\n",
    "!pip install /kaggle/input/mmdetection-offline-lib/terminal-0.4.0-py3-none-any.whl --no-deps\n",
    "!pip install /kaggle/input/mmdetection-offline-lib/mmdet-2.17.0-py3-none-any.whl --no-deps\n",
    "!pip install /kaggle/input/mmdetection-offline-lib/addict-2.4.0-py3-none-any.whl --no-deps\n",
    "!pip install /kaggle/input/mmdetection-offline-lib/yapf-0.31.0-py2.py3-none-any.whl --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06cfa3fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T05:19:17.348514Z",
     "iopub.status.busy": "2023-08-12T05:19:17.346757Z",
     "iopub.status.idle": "2023-08-12T05:19:27.906049Z",
     "shell.execute_reply": "2023-08-12T05:19:27.904864Z"
    },
    "papermill": {
     "duration": 10.573371,
     "end_time": "2023-08-12T05:19:27.908918",
     "exception": false,
     "start_time": "2023-08-12T05:19:17.335547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import math\n",
    "import os\n",
    "import warnings\n",
    "from functools import lru_cache, partial\n",
    "from glob import glob\n",
    "from typing import Callable, List, Tuple\n",
    "\n",
    "import albumentations as albu\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from pytorch_lightning import LightningDataModule, callbacks\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.utilities import rank_zero_info\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from timm.utils import ModelEmaV2\n",
    "\n",
    "from io import StringIO\n",
    "\n",
    "import gc\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "PATCH_SIZE = 32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46a3deb",
   "metadata": {
    "papermill": {
     "duration": 0.009696,
     "end_time": "2023-08-12T05:19:27.928890",
     "exception": false,
     "start_time": "2023-08-12T05:19:27.919194",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Volume to patch(32x32 size npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73e32fc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T05:19:27.951214Z",
     "iopub.status.busy": "2023-08-12T05:19:27.949725Z",
     "iopub.status.idle": "2023-08-12T05:22:19.734496Z",
     "shell.execute_reply": "2023-08-12T05:22:19.733320Z"
    },
    "papermill": {
     "duration": 171.798986,
     "end_time": "2023-08-12T05:22:19.737644",
     "exception": false,
     "start_time": "2023-08-12T05:19:27.938658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14adf033fcd44e128f02f5e4504ab75a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27e3a5c4f2444ec2ab953b645498e8fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac38a29db1e42ba8a362d118d913bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "PREFIX = \"/kaggle/input/vesuvius-challenge-ink-detection/test\"\n",
    "\n",
    "test_fragments = sorted(glob(f\"{PREFIX}/*\"))\n",
    "fragment_ids = [idx.split(\"/\")[-1] for idx in test_fragments]\n",
    "for data_id in tqdm(fragment_ids):\n",
    "    mask = np.array(Image.open(PREFIX + f\"/{data_id}/mask.png\").convert(\"1\"))\n",
    "    volume = np.stack(\n",
    "        [\n",
    "            (np.array(Image.open(filename), dtype=np.float32) / 65535.0).astype(np.float16)\n",
    "            for filename in sorted(\n",
    "                glob(PREFIX + f\"/{data_id}/surface_volume/*.tif\")\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    volume_dir = f\"vesuvius_patches_{PATCH_SIZE}/test/{data_id}/surface_volume/\"\n",
    "    mask_dir = f\"vesuvius_patches_{PATCH_SIZE}/test/{data_id}/mask/\"\n",
    "    os.makedirs(volume_dir, exist_ok=True)\n",
    "    os.makedirs(mask_dir, exist_ok=True)\n",
    "\n",
    "    h, w = volume.shape[-2:]\n",
    "    for i in trange(h // PATCH_SIZE, leave=False):\n",
    "        for j in range(w // PATCH_SIZE):\n",
    "            start_h = i * PATCH_SIZE\n",
    "            start_w = j * PATCH_SIZE\n",
    "            mask_patch = mask[\n",
    "                ..., start_h : start_h + PATCH_SIZE, start_w : start_w + PATCH_SIZE\n",
    "            ]\n",
    "            if not mask_patch.sum():\n",
    "                continue\n",
    "            volume_patch = volume[\n",
    "                ..., start_h : start_h + PATCH_SIZE, start_w : start_w + PATCH_SIZE\n",
    "            ].astype(np.float32)\n",
    "            np.save(os.path.join(volume_dir, f\"volume_{i}_{j}\"), volume_patch)\n",
    "            np.save(os.path.join(mask_dir, f\"mask_{i}_{j}\"), mask_patch)\n",
    "    del volume, mask\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7088fd",
   "metadata": {
    "papermill": {
     "duration": 0.024208,
     "end_time": "2023-08-12T05:22:21.289153",
     "exception": false,
     "start_time": "2023-08-12T05:22:21.264945",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Define dataloader, preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "752d07b9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-08-12T05:22:21.413624Z",
     "iopub.status.busy": "2023-08-12T05:22:21.413029Z",
     "iopub.status.idle": "2023-08-12T05:22:21.492530Z",
     "shell.execute_reply": "2023-08-12T05:22:21.491136Z"
    },
    "papermill": {
     "duration": 0.104432,
     "end_time": "2023-08-12T05:22:21.496037",
     "exception": false,
     "start_time": "2023-08-12T05:22:21.391605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_transforms(train: bool = False) -> Callable:\n",
    "    if train:\n",
    "        return albu.Compose(\n",
    "            [\n",
    "                albu.Flip(p=0.5),\n",
    "                albu.RandomRotate90(p=0.9),\n",
    "                albu.ShiftScaleRotate(\n",
    "                    shift_limit=0.0625,\n",
    "                    scale_limit=0.2,\n",
    "                    rotate_limit=15,\n",
    "                    p=0.9,\n",
    "                ),\n",
    "                albu.OneOf(\n",
    "                    [\n",
    "                        albu.ElasticTransform(p=0.3),\n",
    "                        albu.GaussianBlur(p=0.3),\n",
    "                        albu.GaussNoise(p=0.3),\n",
    "                        albu.OpticalDistortion(p=0.3),\n",
    "                        albu.GridDistortion(p=0.1),\n",
    "                        albu.PiecewiseAffine(p=0.3),  # IAAPiecewiseAffine\n",
    "                    ],\n",
    "                    p=0.9,\n",
    "                ),\n",
    "                albu.RandomBrightnessContrast(\n",
    "                    brightness_limit=0.3, contrast_limit=0.3, p=0.3\n",
    "                ),\n",
    "                ToTensorV2(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        return albu.Compose(\n",
    "            [\n",
    "                ToTensorV2(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "class PatchDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        volume_paths: List[str],\n",
    "        image_size: Tuple[int, int] = (256, 256),\n",
    "        mode: str = \"train\",  # \"train\" | \"valid\" | \"test\"\n",
    "        preprocess_in_model: bool = False,\n",
    "        start_z: int = 8,\n",
    "        end_z: int = -8,\n",
    "        shift_z: int = 2,\n",
    "    ):\n",
    "        self.volume_paths = volume_paths\n",
    "        self.image_size = image_size\n",
    "        assert (image_size[0] % 32 == 0) and (image_size[1] % 32 == 0)\n",
    "        self.mode = mode\n",
    "        self.train = mode == \"train\"\n",
    "        self.transforms = get_transforms(self.train)\n",
    "        self.PATCH_SIZE = 32\n",
    "        self.preprocess_in_model = preprocess_in_model\n",
    "        self.start_z = start_z\n",
    "        self.end_z = end_z\n",
    "        self.shift_z = shift_z\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        if self.mode == \"train\":\n",
    "            return 25000\n",
    "        elif self.mode == \"valid\":\n",
    "            return 24000\n",
    "        else:\n",
    "            return len(self.volume_paths)\n",
    "\n",
    "#     @lru_cache(maxsize=64)\n",
    "    def np_load(self, path: str) -> np.ndarray:\n",
    "        return np.load(path)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, int, int]:\n",
    "        if self.train:\n",
    "            np_load = np.load\n",
    "            idx = np.random.choice(np.arange(len(self.volume_paths)))\n",
    "        else:\n",
    "            np_load = self.np_load\n",
    "        volume = np.zeros((65, *self.image_size), dtype=np.float32)\n",
    "        label = np.zeros(self.image_size)\n",
    "        volume_lt_path = self.volume_paths[idx]\n",
    "        data_prefix = \"/\".join(volume_lt_path.split(\"/\")[:-3])\n",
    "        data_source = volume_lt_path.split(\"/\")[-3]\n",
    "        y, x = volume_lt_path.split(\"/\")[-1].split(\".\")[-2].split(\"_\")[-2:]\n",
    "        x = int(x)\n",
    "        y = int(y)\n",
    "        for i in range(self.image_size[0] // self.PATCH_SIZE):\n",
    "            for j in range(self.image_size[1] // self.PATCH_SIZE):\n",
    "                volume_path = os.path.join(\n",
    "                    data_prefix,\n",
    "                    data_source,\n",
    "                    f\"surface_volume/volume_{y + i}_{x + j}.npy\",\n",
    "                )\n",
    "                label_path = os.path.join(\n",
    "                    data_prefix, data_source, f\"label/label_{y + i}_{x + j}.npy\"\n",
    "                )\n",
    "                if os.path.exists(volume_path):\n",
    "                    volume[\n",
    "                        :,\n",
    "                        i * self.PATCH_SIZE : (i + 1) * self.PATCH_SIZE,\n",
    "                        j * self.PATCH_SIZE : (j + 1) * self.PATCH_SIZE,\n",
    "                    ] = np_load(volume_path)\n",
    "                    if os.path.exists(label_path):\n",
    "                        label[\n",
    "                            i * self.PATCH_SIZE : (i + 1) * self.PATCH_SIZE,\n",
    "                            j * self.PATCH_SIZE : (j + 1) * self.PATCH_SIZE,\n",
    "                        ] = np_load(label_path)\n",
    "        if not self.preprocess_in_model:\n",
    "            if self.train and np.random.rand() < 0.5:\n",
    "                shift = np.random.randint(-self.shift_z, self.shift_z + 1)\n",
    "            else:\n",
    "                shift = 0\n",
    "            # TODO: Add test for shift range\n",
    "            volume = volume[\n",
    "                self.start_z + shift : self.end_z + shift\n",
    "            ]  # use middle 49 layer\n",
    "        volume = volume.transpose(1, 2, 0)\n",
    "        aug = self.transforms(image=volume, mask=label)\n",
    "        volume = aug[\"image\"]\n",
    "        label = aug[\"mask\"][None, :]\n",
    "        if self.train:\n",
    "            volume, label = grid_cutout(\n",
    "                volume=volume, label=label, max_height=2, max_width=2, prob=0.5\n",
    "            )\n",
    "        return (\n",
    "            volume.half(),\n",
    "            label.half(),\n",
    "            x,\n",
    "            y,\n",
    "        )\n",
    "\n",
    "\n",
    "class InkDetDataModule(LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_volume_paths: List[str],\n",
    "        valid_volume_paths: List[str],\n",
    "        image_size: int = 256,\n",
    "        num_workers: int = 4,\n",
    "        batch_size: int = 16,\n",
    "        preprocess_in_model: bool = False,\n",
    "        start_z: int = 8,\n",
    "        end_z: int = -8,\n",
    "        shift_z: int = 2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self._num_workers = num_workers\n",
    "        self._batch_size = batch_size\n",
    "        self.train_volume_paths = train_volume_paths\n",
    "        self.valid_volume_paths = valid_volume_paths\n",
    "        self.image_size = (image_size, image_size)\n",
    "        self.preprocess_in_model = preprocess_in_model\n",
    "        self.start_z = start_z\n",
    "        self.end_z = end_z\n",
    "        self.shift_z = shift_z\n",
    "        self.save_hyperparameters(\n",
    "            \"num_workers\",\n",
    "            \"batch_size\",\n",
    "            \"image_size\",\n",
    "            \"preprocess_in_model\",\n",
    "            \"start_z\",\n",
    "            \"end_z\",\n",
    "            \"shift_z\",\n",
    "        )\n",
    "\n",
    "    def create_dataset(self, mode: str = \"train\") -> PatchDataset:\n",
    "        if mode == \"train\":\n",
    "            return PatchDataset(\n",
    "                volume_paths=self.train_volume_paths,\n",
    "                image_size=self.image_size,\n",
    "                mode=mode,\n",
    "                preprocess_in_model=self.preprocess_in_model,\n",
    "                start_z=self.start_z,\n",
    "                end_z=self.end_z,\n",
    "                shift_z=self.shift_z,\n",
    "            )\n",
    "        else:\n",
    "            return PatchDataset(\n",
    "                volume_paths=self.valid_volume_paths,\n",
    "                image_size=self.image_size,\n",
    "                mode=mode,\n",
    "                preprocess_in_model=self.preprocess_in_model,\n",
    "                start_z=self.start_z,\n",
    "                end_z=self.end_z,\n",
    "                shift_z=self.shift_z,\n",
    "            )\n",
    "\n",
    "    def __dataloader(self, mode: str = \"train\") -> DataLoader:\n",
    "        \"\"\"Train/validation loaders.\"\"\"\n",
    "        dataset = self.create_dataset(mode)\n",
    "        return DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=self._batch_size,\n",
    "            num_workers=self._num_workers,\n",
    "            shuffle=(mode == \"train\"),\n",
    "            drop_last=(mode == \"train\"),\n",
    "            # worker_init_fn=lambda x: np.random.seed(np.random.get_state()[1][0] + x),\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return self.__dataloader(mode=\"train\")\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return self.__dataloader(mode=\"valid\")\n",
    "\n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        return self.__dataloader(mode=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d445c757",
   "metadata": {
    "papermill": {
     "duration": 0.018422,
     "end_time": "2023-08-12T05:22:21.537149",
     "exception": false,
     "start_time": "2023-08-12T05:22:21.518727",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Define 2.5D_3DCNN Model (timm backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb631127",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-08-12T05:22:21.588598Z",
     "iopub.status.busy": "2023-08-12T05:22:21.587394Z",
     "iopub.status.idle": "2023-08-12T05:22:21.641732Z",
     "shell.execute_reply": "2023-08-12T05:22:21.640695Z"
    },
    "papermill": {
     "duration": 0.084335,
     "end_time": "2023-08-12T05:22:21.644132",
     "exception": false,
     "start_time": "2023-08-12T05:22:21.559797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def downsample_conv(\n",
    "    in_channels: int,\n",
    "    out_channels: int,\n",
    "    stride: int = 2,\n",
    "):\n",
    "    return nn.Sequential(\n",
    "        *[\n",
    "            nn.Conv3d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                1,\n",
    "                stride=(1, stride, stride),\n",
    "                padding=0,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "class ResidualConv3D(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        mid_channels: int,\n",
    "        out_channels: int,\n",
    "        stride: int = 2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv3d(in_channels, mid_channels, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(mid_channels)\n",
    "        self.act1 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv3d(mid_channels, mid_channels, kernel_size=1, stride=1, bias=False),\n",
    "            nn.Conv3d(\n",
    "                mid_channels,\n",
    "                mid_channels,\n",
    "                kernel_size=3,\n",
    "                stride=(1, stride, stride),\n",
    "                padding=1,\n",
    "                bias=False,\n",
    "                groups=mid_channels,\n",
    "            ),\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm3d(mid_channels)\n",
    "        self.act2 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv3 = nn.Conv3d(mid_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm3d(out_channels)\n",
    "\n",
    "        self.act3 = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample_conv(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            stride=stride,\n",
    "        )\n",
    "        self.stride = stride\n",
    "        self.zero_init_last()\n",
    "\n",
    "    def zero_init_last(self):\n",
    "        if getattr(self.bn3, \"weight\", None) is not None:\n",
    "            nn.init.zeros_(self.bn3.weight)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        shortcut = x\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.act2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            shortcut = self.downsample(shortcut)\n",
    "        x += shortcut\n",
    "        x = self.act3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class InkDetModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"resnet34\",\n",
    "        pretrained: bool = False,\n",
    "        drop_rate: float = 0,\n",
    "        drop_path_rate: float = 0,\n",
    "        num_3d_layer: int = 3,\n",
    "        in_chans: int = 7,\n",
    "        preprocess_in_model: bool = False,\n",
    "        start_z: int = 8,\n",
    "        end_z: int = -8,\n",
    "        shift_z: int = 2,\n",
    "        num_class: int = 1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder = timm.create_model(\n",
    "            model_name,\n",
    "            pretrained=pretrained,\n",
    "            in_chans=in_chans,\n",
    "            features_only=True,\n",
    "            drop_rate=drop_rate,\n",
    "            drop_path_rate=drop_path_rate,\n",
    "        )\n",
    "        self.output_fmt = getattr(self.encoder, \"output_fmt\", \"NHCW\")\n",
    "        self.in_chans = in_chans\n",
    "        num_features = self.encoder.feature_info.channels()[-1]\n",
    "        self.conv_proj = nn.Sequential(\n",
    "            nn.Conv2d(num_features, 512, 1, stride=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv3d = nn.Sequential(\n",
    "            *[\n",
    "                ResidualConv3D(\n",
    "                    512,\n",
    "                    512,\n",
    "                    512,\n",
    "                    1,\n",
    "                )\n",
    "                for _ in range(num_3d_layer)\n",
    "            ]\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                512 * 2,\n",
    "                512,\n",
    "                1,\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.Conv2d(\n",
    "                512,\n",
    "                num_class,\n",
    "                1,\n",
    "            ),\n",
    "        )\n",
    "        self.preprocess_in_model = preprocess_in_model\n",
    "        self.start_z = start_z\n",
    "        self.end_z = end_z\n",
    "        self.shift_z = shift_z\n",
    "\n",
    "    def preprocess(self, img):\n",
    "        if self.training and np.random.rand() < 0.5:\n",
    "            shift = np.random.randint(-self.shift_z, self.shift_z + 1)\n",
    "        else:\n",
    "            shift = 0\n",
    "        img = img[:, self.start_z + shift : self.end_z + shift]\n",
    "        return img\n",
    "\n",
    "    def forward_image_feats(self, img):\n",
    "        if self.preprocess_in_model:\n",
    "            img = self.preprocess(img)\n",
    "        mean = img.mean(dim=(1, 2, 3), keepdim=True)\n",
    "        std = img.std(dim=(1, 2, 3), keepdim=True) + 1e-6\n",
    "        img = (img - mean) / std\n",
    "        bs, ch, h, w = img.shape\n",
    "        assert ch % self.in_chans == 0\n",
    "        groups_3d = ch // self.in_chans\n",
    "        img = img.reshape((bs, groups_3d, self.in_chans, h, w))\n",
    "\n",
    "        if self.training:\n",
    "            ch_arr = list(range(img.shape[2]))\n",
    "            ch_arr = [\n",
    "                random.sample(ch_arr, len(ch_arr)) if np.random.rand() < 0.2 else ch_arr\n",
    "                for _ in range(img.shape[0])\n",
    "            ]\n",
    "            for i, ca in enumerate(ch_arr):\n",
    "                img[i] = img[i, :, ca]\n",
    "        img = img.reshape(bs * groups_3d, self.in_chans, h, w)\n",
    "        img_feat = self.encoder(img)[-1]\n",
    "        if self.output_fmt == \"NHWC\":\n",
    "            img_feat = img_feat.permute(0, 3, 1, 2).contiguous()\n",
    "        img_feat = self.conv_proj(img_feat)  # (bs * groups_3d, 512, h, w)\n",
    "        _, ch, h, w = img_feat.shape\n",
    "        img_feat = img_feat.reshape(bs, groups_3d, ch, h, w).transpose(\n",
    "            1, 2\n",
    "        )  # (bs, ch, groups_3d, h, w)\n",
    "        img_feat = self.conv3d(img_feat)  # (bs, ch, groups_3d, h, w)\n",
    "        img_feat = torch.cat([img_feat.mean(2), img_feat.max(2)[0]], 1)\n",
    "        return img_feat\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        img: torch.Tensor,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        img: (bs, ch, h, w)\n",
    "        \"\"\"\n",
    "        img_feat = self.forward_image_feats(img)\n",
    "        return self.head(img_feat)\n",
    "\n",
    "\n",
    "class InkDetLightningModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        valid_fragment_id: str,\n",
    "        model_name: str = \"resnet34\",\n",
    "        pretrained: bool = False,\n",
    "        drop_rate: float = 0,\n",
    "        drop_path_rate: float = 0,\n",
    "        num_3d_layer: int = 3,\n",
    "        in_chans: int = 7,\n",
    "        preprocess_in_model: bool = False,\n",
    "        start_z: int = 8,\n",
    "        end_z: int = -8,\n",
    "        shift_z: int = 2,\n",
    "        mixup_p: float = 0.0,\n",
    "        mixup_alpha: float = 0.5,\n",
    "        no_mixup_epochs: int = 0,\n",
    "        lr: float = 1e-3,\n",
    "        backbone_lr: float = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.__build_model(\n",
    "            model_name=model_name,\n",
    "            pretrained=pretrained,\n",
    "            drop_rate=drop_rate,\n",
    "            drop_path_rate=drop_path_rate,\n",
    "            num_3d_layer=num_3d_layer,\n",
    "            preprocess_in_model=preprocess_in_model,\n",
    "            start_z=start_z,\n",
    "            end_z=end_z,\n",
    "            shift_z=shift_z,\n",
    "            in_chans=in_chans,\n",
    "        )\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def __build_model(\n",
    "        self,\n",
    "        model_name: str = \"resnet34\",\n",
    "        pretrained: bool = False,\n",
    "        drop_rate: float = 0,\n",
    "        drop_path_rate: float = 0,\n",
    "        num_3d_layer: int = 3,\n",
    "        in_chans: int = 7,\n",
    "        preprocess_in_model: bool = False,\n",
    "        start_z: int = 8,\n",
    "        end_z: int = -8,\n",
    "        shift_z: int = 2,\n",
    "    ):\n",
    "        self.model = InkDetModel(\n",
    "            model_name=model_name,\n",
    "            pretrained=pretrained,\n",
    "            drop_rate=drop_rate,\n",
    "            drop_path_rate=drop_path_rate,\n",
    "            num_3d_layer=num_3d_layer,\n",
    "            in_chans=in_chans,\n",
    "            preprocess_in_model=preprocess_in_model,\n",
    "            start_z=start_z,\n",
    "            end_z=end_z,\n",
    "            shift_z=shift_z,\n",
    "            num_class=1,\n",
    "        )\n",
    "        self.model_ema = ModelEmaV2(self.model, decay=0.99)\n",
    "        \n",
    "    def predict(self, volume):\n",
    "        output = torch.sigmoid(self.model_ema.module(volume))\n",
    "        output = F.interpolate(\n",
    "            output.float(),\n",
    "            scale_factor=32,\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=True,\n",
    "        ).half()\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a8f01e",
   "metadata": {
    "papermill": {
     "duration": 0.010104,
     "end_time": "2023-08-12T05:22:21.664575",
     "exception": false,
     "start_time": "2023-08-12T05:22:21.654471",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define ResNet3DCSN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f149d31",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-08-12T05:22:21.688036Z",
     "iopub.status.busy": "2023-08-12T05:22:21.687720Z",
     "iopub.status.idle": "2023-08-12T05:22:37.614306Z",
     "shell.execute_reply": "2023-08-12T05:22:37.613044Z"
    },
    "papermill": {
     "duration": 15.94227,
     "end_time": "2023-08-12T05:22:37.617116",
     "exception": false,
     "start_time": "2023-08-12T05:22:21.674846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copyright (c) OpenMMLab. All rights reserved.\n",
    "\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "import torch.utils.checkpoint as cp\n",
    "from mmcv.cnn import (\n",
    "    ConvModule,\n",
    "    NonLocal3d,\n",
    "    build_activation_layer,\n",
    "    constant_init,\n",
    "    kaiming_init,\n",
    ")\n",
    "from mmcv.runner import _load_checkpoint, load_checkpoint\n",
    "from timm.layers import DropPath\n",
    "from torch import nn\n",
    "from torch.nn.modules.batchnorm import _BatchNorm\n",
    "from torch.nn.modules.utils import _ntuple, _triple\n",
    "\n",
    "\n",
    "class BasicBlock3d(nn.Module):\n",
    "    \"\"\"BasicBlock 3d block for ResNet3D.\n",
    "    Args:\n",
    "        inplanes (int): Number of channels for the input in first conv3d layer.\n",
    "        planes (int): Number of channels produced by some norm/conv3d layers.\n",
    "        spatial_stride (int): Spatial stride in the conv3d layer. Default: 1.\n",
    "        temporal_stride (int): Temporal stride in the conv3d layer. Default: 1.\n",
    "        dilation (int): Spacing between kernel elements. Default: 1.\n",
    "        downsample (nn.Module | None): Downsample layer. Default: None.\n",
    "        style (str): ``pytorch`` or ``caffe``. If set to \"pytorch\", the\n",
    "            stride-two layer is the 3x3 conv layer, otherwise the stride-two\n",
    "            layer is the first 1x1 conv layer. Default: 'pytorch'.\n",
    "        inflate (bool): Whether to inflate kernel. Default: True.\n",
    "        non_local (bool): Determine whether to apply non-local module in this\n",
    "            block. Default: False.\n",
    "        non_local_cfg (dict): Config for non-local module. Default: ``dict()``.\n",
    "        conv_cfg (dict): Config dict for convolution layer.\n",
    "            Default: ``dict(type='Conv3d')``.\n",
    "        norm_cfg (dict): Config for norm layers. required keys are ``type``,\n",
    "            Default: ``dict(type='BN3d')``.\n",
    "        act_cfg (dict): Config dict for activation layer.\n",
    "            Default: ``dict(type='ReLU')``.\n",
    "        with_cp (bool): Use checkpoint or not. Using checkpoint will save some\n",
    "            memory while slowing down the training speed. Default: False.\n",
    "    \"\"\"\n",
    "\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes,\n",
    "        planes,\n",
    "        spatial_stride=1,\n",
    "        temporal_stride=1,\n",
    "        dilation=1,\n",
    "        downsample=None,\n",
    "        style=\"pytorch\",\n",
    "        inflate=True,\n",
    "        non_local=False,\n",
    "        non_local_cfg=dict(),\n",
    "        conv_cfg=dict(type=\"Conv3d\"),\n",
    "        norm_cfg=dict(type=\"BN3d\"),\n",
    "        act_cfg=dict(type=\"ReLU\"),\n",
    "        with_cp=False,\n",
    "        drop_path=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert style in [\"pytorch\", \"caffe\"]\n",
    "        # make sure that only ``inflate_style`` is passed into kwargs\n",
    "        assert set(kwargs).issubset([\"inflate_style\"])\n",
    "\n",
    "        self.inplanes = inplanes\n",
    "        self.planes = planes\n",
    "        self.spatial_stride = spatial_stride\n",
    "        self.temporal_stride = temporal_stride\n",
    "        self.dilation = dilation\n",
    "        self.style = style\n",
    "        self.inflate = inflate\n",
    "        self.conv_cfg = conv_cfg\n",
    "        self.norm_cfg = norm_cfg\n",
    "        self.act_cfg = act_cfg\n",
    "        self.with_cp = with_cp\n",
    "        self.non_local = non_local\n",
    "        self.non_local_cfg = non_local_cfg\n",
    "\n",
    "        self.conv1_stride_s = spatial_stride\n",
    "        self.conv2_stride_s = 1\n",
    "        self.conv1_stride_t = temporal_stride\n",
    "        self.conv2_stride_t = 1\n",
    "\n",
    "        if self.inflate:\n",
    "            conv1_kernel_size = (3, 3, 3)\n",
    "            conv1_padding = (1, dilation, dilation)\n",
    "            conv2_kernel_size = (3, 3, 3)\n",
    "            conv2_padding = (1, 1, 1)\n",
    "        else:\n",
    "            conv1_kernel_size = (1, 3, 3)\n",
    "            conv1_padding = (0, dilation, dilation)\n",
    "            conv2_kernel_size = (1, 3, 3)\n",
    "            conv2_padding = (0, 1, 1)\n",
    "\n",
    "        self.conv1 = ConvModule(\n",
    "            inplanes,\n",
    "            planes,\n",
    "            conv1_kernel_size,\n",
    "            stride=(self.conv1_stride_t, self.conv1_stride_s, self.conv1_stride_s),\n",
    "            padding=conv1_padding,\n",
    "            dilation=(1, dilation, dilation),\n",
    "            bias=False,\n",
    "            conv_cfg=self.conv_cfg,\n",
    "            norm_cfg=self.norm_cfg,\n",
    "            act_cfg=self.act_cfg,\n",
    "        )\n",
    "\n",
    "        self.conv2 = ConvModule(\n",
    "            planes,\n",
    "            planes * self.expansion,\n",
    "            conv2_kernel_size,\n",
    "            stride=(self.conv2_stride_t, self.conv2_stride_s, self.conv2_stride_s),\n",
    "            padding=conv2_padding,\n",
    "            bias=False,\n",
    "            conv_cfg=self.conv_cfg,\n",
    "            norm_cfg=self.norm_cfg,\n",
    "            act_cfg=None,\n",
    "        )\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.relu = build_activation_layer(self.act_cfg)\n",
    "\n",
    "        if self.non_local:\n",
    "            self.non_local_block = NonLocal3d(\n",
    "                self.conv2.norm.num_features, **self.non_local_cfg\n",
    "            )\n",
    "        self.drop_path = drop_path\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Defines the computation performed at every call.\"\"\"\n",
    "\n",
    "        def _inner_forward(x):\n",
    "            \"\"\"Forward wrapper for utilizing checkpoint.\"\"\"\n",
    "            identity = x\n",
    "\n",
    "            out = self.conv1(x)\n",
    "            out = self.conv2(out)\n",
    "            if self.drop_path is not None:\n",
    "                x = self.drop_path(x)\n",
    "            if self.downsample is not None:\n",
    "                identity = self.downsample(x)\n",
    "\n",
    "            out = out + identity\n",
    "            return out\n",
    "\n",
    "        if self.with_cp and x.requires_grad:\n",
    "            out = cp.checkpoint(_inner_forward, x)\n",
    "        else:\n",
    "            out = _inner_forward(x)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        if self.non_local:\n",
    "            out = self.non_local_block(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck3d(nn.Module):\n",
    "    \"\"\"Bottleneck 3d block for ResNet3D.\n",
    "    Args:\n",
    "        inplanes (int): Number of channels for the input in first conv3d layer.\n",
    "        planes (int): Number of channels produced by some norm/conv3d layers.\n",
    "        spatial_stride (int): Spatial stride in the conv3d layer. Default: 1.\n",
    "        temporal_stride (int): Temporal stride in the conv3d layer. Default: 1.\n",
    "        dilation (int): Spacing between kernel elements. Default: 1.\n",
    "        downsample (nn.Module | None): Downsample layer. Default: None.\n",
    "        style (str): ``pytorch`` or ``caffe``. If set to \"pytorch\", the\n",
    "            stride-two layer is the 3x3 conv layer, otherwise the stride-two\n",
    "            layer is the first 1x1 conv layer. Default: 'pytorch'.\n",
    "        inflate (bool): Whether to inflate kernel. Default: True.\n",
    "        inflate_style (str): ``3x1x1`` or ``3x3x3``. which determines the\n",
    "            kernel sizes and padding strides for conv1 and conv2 in each block.\n",
    "            Default: '3x1x1'.\n",
    "        non_local (bool): Determine whether to apply non-local module in this\n",
    "            block. Default: False.\n",
    "        non_local_cfg (dict): Config for non-local module. Default: ``dict()``.\n",
    "        conv_cfg (dict): Config dict for convolution layer.\n",
    "            Default: ``dict(type='Conv3d')``.\n",
    "        norm_cfg (dict): Config for norm layers. required keys are ``type``,\n",
    "            Default: ``dict(type='BN3d')``.\n",
    "        act_cfg (dict): Config dict for activation layer.\n",
    "            Default: ``dict(type='ReLU')``.\n",
    "        with_cp (bool): Use checkpoint or not. Using checkpoint will save some\n",
    "            memory while slowing down the training speed. Default: False.\n",
    "    \"\"\"\n",
    "\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes,\n",
    "        planes,\n",
    "        spatial_stride=1,\n",
    "        temporal_stride=1,\n",
    "        dilation=1,\n",
    "        downsample=None,\n",
    "        style=\"pytorch\",\n",
    "        inflate=True,\n",
    "        inflate_style=\"3x1x1\",\n",
    "        non_local=False,\n",
    "        non_local_cfg=dict(),\n",
    "        conv_cfg=dict(type=\"Conv3d\"),\n",
    "        norm_cfg=dict(type=\"BN3d\"),\n",
    "        act_cfg=dict(type=\"ReLU\"),\n",
    "        with_cp=False,\n",
    "        drop_path=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert style in [\"pytorch\", \"caffe\"]\n",
    "        assert inflate_style in [\"3x1x1\", \"3x3x3\"]\n",
    "\n",
    "        self.inplanes = inplanes\n",
    "        self.planes = planes\n",
    "        self.spatial_stride = spatial_stride\n",
    "        self.temporal_stride = temporal_stride\n",
    "        self.dilation = dilation\n",
    "        self.style = style\n",
    "        self.inflate = inflate\n",
    "        self.inflate_style = inflate_style\n",
    "        self.norm_cfg = norm_cfg\n",
    "        self.conv_cfg = conv_cfg\n",
    "        self.act_cfg = act_cfg\n",
    "        self.with_cp = with_cp\n",
    "        self.non_local = non_local\n",
    "        self.non_local_cfg = non_local_cfg\n",
    "\n",
    "        if self.style == \"pytorch\":\n",
    "            self.conv1_stride_s = 1\n",
    "            self.conv2_stride_s = spatial_stride\n",
    "            self.conv1_stride_t = 1\n",
    "            self.conv2_stride_t = temporal_stride\n",
    "        else:\n",
    "            self.conv1_stride_s = spatial_stride\n",
    "            self.conv2_stride_s = 1\n",
    "            self.conv1_stride_t = temporal_stride\n",
    "            self.conv2_stride_t = 1\n",
    "\n",
    "        if self.inflate:\n",
    "            if inflate_style == \"3x1x1\":\n",
    "                conv1_kernel_size = (3, 1, 1)\n",
    "                conv1_padding = (1, 0, 0)\n",
    "                conv2_kernel_size = (1, 3, 3)\n",
    "                conv2_padding = (0, dilation, dilation)\n",
    "            else:\n",
    "                conv1_kernel_size = (1, 1, 1)\n",
    "                conv1_padding = (0, 0, 0)\n",
    "                conv2_kernel_size = (3, 3, 3)\n",
    "                conv2_padding = (1, dilation, dilation)\n",
    "        else:\n",
    "            conv1_kernel_size = (1, 1, 1)\n",
    "            conv1_padding = (0, 0, 0)\n",
    "            conv2_kernel_size = (1, 3, 3)\n",
    "            conv2_padding = (0, dilation, dilation)\n",
    "\n",
    "        self.conv1 = ConvModule(\n",
    "            inplanes,\n",
    "            planes,\n",
    "            conv1_kernel_size,\n",
    "            stride=(self.conv1_stride_t, self.conv1_stride_s, self.conv1_stride_s),\n",
    "            padding=conv1_padding,\n",
    "            bias=False,\n",
    "            conv_cfg=self.conv_cfg,\n",
    "            norm_cfg=self.norm_cfg,\n",
    "            act_cfg=self.act_cfg,\n",
    "        )\n",
    "\n",
    "        self.conv2 = ConvModule(\n",
    "            planes,\n",
    "            planes,\n",
    "            conv2_kernel_size,\n",
    "            stride=(self.conv2_stride_t, self.conv2_stride_s, self.conv2_stride_s),\n",
    "            padding=conv2_padding,\n",
    "            dilation=(1, dilation, dilation),\n",
    "            bias=False,\n",
    "            conv_cfg=self.conv_cfg,\n",
    "            norm_cfg=self.norm_cfg,\n",
    "            act_cfg=self.act_cfg,\n",
    "        )\n",
    "\n",
    "        self.conv3 = ConvModule(\n",
    "            planes,\n",
    "            planes * self.expansion,\n",
    "            1,\n",
    "            bias=False,\n",
    "            conv_cfg=self.conv_cfg,\n",
    "            norm_cfg=self.norm_cfg,\n",
    "            # No activation in the third ConvModule for bottleneck\n",
    "            act_cfg=None,\n",
    "        )\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.relu = build_activation_layer(self.act_cfg)\n",
    "\n",
    "        if self.non_local:\n",
    "            self.non_local_block = NonLocal3d(\n",
    "                self.conv3.norm.num_features, **self.non_local_cfg\n",
    "            )\n",
    "        self.drop_path = drop_path\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Defines the computation performed at every call.\"\"\"\n",
    "\n",
    "        def _inner_forward(x):\n",
    "            \"\"\"Forward wrapper for utilizing checkpoint.\"\"\"\n",
    "            identity = x\n",
    "\n",
    "            out = self.conv1(x)\n",
    "            out = self.conv2(out)\n",
    "            out = self.conv3(out)\n",
    "\n",
    "            if self.drop_path is not None:\n",
    "                x = self.drop_path(x)\n",
    "\n",
    "            if self.downsample is not None:\n",
    "                identity = self.downsample(x)\n",
    "\n",
    "            out = out + identity\n",
    "            return out\n",
    "\n",
    "        if self.with_cp and x.requires_grad:\n",
    "            out = cp.checkpoint(_inner_forward, x)\n",
    "        else:\n",
    "            out = _inner_forward(x)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        if self.non_local:\n",
    "            out = self.non_local_block(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet3d(nn.Module):\n",
    "    \"\"\"ResNet 3d backbone.\n",
    "    Args:\n",
    "        depth (int): Depth of resnet, from {18, 34, 50, 101, 152}.\n",
    "        pretrained (str | None): Name of pretrained model.\n",
    "        stage_blocks (tuple | None): Set number of stages for each res layer.\n",
    "            Default: None.\n",
    "        pretrained2d (bool): Whether to load pretrained 2D model.\n",
    "            Default: True.\n",
    "        in_channels (int): Channel num of input features. Default: 3.\n",
    "        base_channels (int): Channel num of stem output features. Default: 64.\n",
    "        out_indices (Sequence[int]): Indices of output feature. Default: (3, ).\n",
    "        num_stages (int): Resnet stages. Default: 4.\n",
    "        spatial_strides (Sequence[int]):\n",
    "            Spatial strides of residual blocks of each stage.\n",
    "            Default: ``(1, 2, 2, 2)``.\n",
    "        temporal_strides (Sequence[int]):\n",
    "            Temporal strides of residual blocks of each stage.\n",
    "            Default: ``(1, 1, 1, 1)``.\n",
    "        dilations (Sequence[int]): Dilation of each stage.\n",
    "            Default: ``(1, 1, 1, 1)``.\n",
    "        conv1_kernel (Sequence[int]): Kernel size of the first conv layer.\n",
    "            Default: ``(3, 7, 7)``.\n",
    "        conv1_stride_s (int): Spatial stride of the first conv layer.\n",
    "            Default: 2.\n",
    "        conv1_stride_t (int): Temporal stride of the first conv layer.\n",
    "            Default: 1.\n",
    "        pool1_stride_s (int): Spatial stride of the first pooling layer.\n",
    "            Default: 2.\n",
    "        pool1_stride_t (int): Temporal stride of the first pooling layer.\n",
    "            Default: 1.\n",
    "        with_pool2 (bool): Whether to use pool2. Default: True.\n",
    "        style (str): `pytorch` or `caffe`. If set to \"pytorch\", the stride-two\n",
    "            layer is the 3x3 conv layer, otherwise the stride-two layer is\n",
    "            the first 1x1 conv layer. Default: 'pytorch'.\n",
    "        frozen_stages (int): Stages to be frozen (all param fixed). -1 means\n",
    "            not freezing any parameters. Default: -1.\n",
    "        inflate (Sequence[int]): Inflate Dims of each block.\n",
    "            Default: (1, 1, 1, 1).\n",
    "        inflate_style (str): ``3x1x1`` or ``3x3x3``. which determines the\n",
    "            kernel sizes and padding strides for conv1 and conv2 in each block.\n",
    "            Default: '3x1x1'.\n",
    "        conv_cfg (dict): Config for conv layers. required keys are ``type``\n",
    "            Default: ``dict(type='Conv3d')``.\n",
    "        norm_cfg (dict): Config for norm layers. required keys are ``type`` and\n",
    "            ``requires_grad``.\n",
    "            Default: ``dict(type='BN3d', requires_grad=True)``.\n",
    "        act_cfg (dict): Config dict for activation layer.\n",
    "            Default: ``dict(type='ReLU', inplace=True)``.\n",
    "        norm_eval (bool): Whether to set BN layers to eval mode, namely, freeze\n",
    "            running stats (mean and var). Default: False.\n",
    "        with_cp (bool): Use checkpoint or not. Using checkpoint will save some\n",
    "            memory while slowing down the training speed. Default: False.\n",
    "        non_local (Sequence[int]): Determine whether to apply non-local module\n",
    "            in the corresponding block of each stages. Default: (0, 0, 0, 0).\n",
    "        non_local_cfg (dict): Config for non-local module. Default: ``dict()``.\n",
    "        zero_init_residual (bool):\n",
    "            Whether to use zero initialization for residual block,\n",
    "            Default: True.\n",
    "        kwargs (dict, optional): Key arguments for \"make_res_layer\".\n",
    "    \"\"\"\n",
    "\n",
    "    arch_settings = {\n",
    "        18: (BasicBlock3d, (2, 2, 2, 2)),\n",
    "        34: (BasicBlock3d, (3, 4, 6, 3)),\n",
    "        50: (Bottleneck3d, (3, 4, 6, 3)),\n",
    "        101: (Bottleneck3d, (3, 4, 23, 3)),\n",
    "        152: (Bottleneck3d, (3, 8, 36, 3)),\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        depth,\n",
    "        pretrained,\n",
    "        stage_blocks=None,\n",
    "        pretrained2d=True,\n",
    "        in_channels=3,\n",
    "        num_stages=4,\n",
    "        base_channels=64,\n",
    "        out_indices=(\n",
    "            0,\n",
    "            1,\n",
    "            2,\n",
    "            3,\n",
    "        ),\n",
    "        spatial_strides=(1, 2, 2, 2),\n",
    "        temporal_strides=(1, 1, 1, 1),\n",
    "        dilations=(1, 1, 1, 1),\n",
    "        conv1_kernel=(3, 7, 7),\n",
    "        conv1_stride_s=2,\n",
    "        conv1_stride_t=1,\n",
    "        pool1_stride_s=2,\n",
    "        pool1_stride_t=1,\n",
    "        with_pool1=True,\n",
    "        with_pool2=True,\n",
    "        style=\"pytorch\",\n",
    "        frozen_stages=-1,\n",
    "        inflate=(1, 1, 1, 1),\n",
    "        inflate_style=\"3x1x1\",\n",
    "        conv_cfg=dict(type=\"Conv3d\"),\n",
    "        norm_cfg=dict(type=\"BN3d\", requires_grad=True),\n",
    "        act_cfg=dict(type=\"ReLU\", inplace=True),\n",
    "        norm_eval=False,\n",
    "        with_cp=False,\n",
    "        non_local=(0, 0, 0, 0),\n",
    "        non_local_cfg=dict(),\n",
    "        zero_init_residual=True,\n",
    "        drop_path_rate=0.0,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if depth not in self.arch_settings:\n",
    "            raise KeyError(f\"invalid depth {depth} for resnet\")\n",
    "        self.depth = depth\n",
    "        self.pretrained = pretrained\n",
    "        self.pretrained2d = pretrained2d\n",
    "        self.in_channels = in_channels\n",
    "        self.base_channels = base_channels\n",
    "        self.num_stages = num_stages\n",
    "        assert 1 <= num_stages <= 4\n",
    "        self.stage_blocks = stage_blocks\n",
    "        self.out_indices = out_indices\n",
    "        assert max(out_indices) < num_stages\n",
    "        self.spatial_strides = spatial_strides\n",
    "        self.temporal_strides = temporal_strides\n",
    "        self.dilations = dilations\n",
    "        assert (\n",
    "            len(spatial_strides)\n",
    "            == len(temporal_strides)\n",
    "            == len(dilations)\n",
    "            == num_stages\n",
    "        )\n",
    "        if self.stage_blocks is not None:\n",
    "            assert len(self.stage_blocks) == num_stages\n",
    "\n",
    "        self.conv1_kernel = conv1_kernel\n",
    "        self.conv1_stride_s = conv1_stride_s\n",
    "        self.conv1_stride_t = conv1_stride_t\n",
    "        self.pool1_stride_s = pool1_stride_s\n",
    "        self.pool1_stride_t = pool1_stride_t\n",
    "        self.with_pool1 = with_pool1\n",
    "        self.with_pool2 = with_pool2\n",
    "        self.style = style\n",
    "        self.frozen_stages = frozen_stages\n",
    "        self.stage_inflations = _ntuple(num_stages)(inflate)\n",
    "        self.non_local_stages = _ntuple(num_stages)(non_local)\n",
    "        self.inflate_style = inflate_style\n",
    "        self.conv_cfg = conv_cfg\n",
    "        self.norm_cfg = norm_cfg\n",
    "        self.act_cfg = act_cfg\n",
    "        self.norm_eval = norm_eval\n",
    "        self.with_cp = with_cp\n",
    "        self.zero_init_residual = zero_init_residual\n",
    "\n",
    "        self.block, stage_blocks = self.arch_settings[depth]\n",
    "\n",
    "        if self.stage_blocks is None:\n",
    "            self.stage_blocks = stage_blocks[:num_stages]\n",
    "\n",
    "        self.inplanes = self.base_channels\n",
    "\n",
    "        self.non_local_cfg = non_local_cfg\n",
    "\n",
    "        self._make_stem_layer()\n",
    "\n",
    "        self.res_layers = []\n",
    "        for i, num_blocks in enumerate(self.stage_blocks):\n",
    "            spatial_stride = spatial_strides[i]\n",
    "            temporal_stride = temporal_strides[i]\n",
    "            dilation = dilations[i]\n",
    "            planes = self.base_channels * 2**i\n",
    "            res_layer = self.make_res_layer(\n",
    "                self.block,\n",
    "                self.inplanes,\n",
    "                planes,\n",
    "                num_blocks,\n",
    "                spatial_stride=spatial_stride,\n",
    "                temporal_stride=temporal_stride,\n",
    "                dilation=dilation,\n",
    "                style=self.style,\n",
    "                norm_cfg=self.norm_cfg,\n",
    "                conv_cfg=self.conv_cfg,\n",
    "                act_cfg=self.act_cfg,\n",
    "                non_local=self.non_local_stages[i],\n",
    "                non_local_cfg=self.non_local_cfg,\n",
    "                inflate=self.stage_inflations[i],\n",
    "                inflate_style=self.inflate_style,\n",
    "                with_cp=with_cp,\n",
    "                drop_path_rate=drop_path_rate,\n",
    "                **kwargs,\n",
    "            )\n",
    "            self.inplanes = planes * self.block.expansion\n",
    "            layer_name = f\"layer{i + 1}\"\n",
    "            self.add_module(layer_name, res_layer)\n",
    "            self.res_layers.append(layer_name)\n",
    "\n",
    "        self.feat_dim = (\n",
    "            self.block.expansion\n",
    "            * self.base_channels\n",
    "            * 2 ** (len(self.stage_blocks) - 1)\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def make_res_layer(\n",
    "        block,\n",
    "        inplanes,\n",
    "        planes,\n",
    "        blocks,\n",
    "        spatial_stride=1,\n",
    "        temporal_stride=1,\n",
    "        dilation=1,\n",
    "        style=\"pytorch\",\n",
    "        inflate=1,\n",
    "        inflate_style=\"3x1x1\",\n",
    "        non_local=0,\n",
    "        non_local_cfg=dict(),\n",
    "        norm_cfg=None,\n",
    "        act_cfg=None,\n",
    "        conv_cfg=None,\n",
    "        with_cp=False,\n",
    "        drop_path_rate=0.0,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Build residual layer for ResNet3D.\n",
    "        Args:\n",
    "            block (nn.Module): Residual module to be built.\n",
    "            inplanes (int): Number of channels for the input feature\n",
    "                in each block.\n",
    "            planes (int): Number of channels for the output feature\n",
    "                in each block.\n",
    "            blocks (int): Number of residual blocks.\n",
    "            spatial_stride (int | Sequence[int]): Spatial strides in\n",
    "                residual and conv layers. Default: 1.\n",
    "            temporal_stride (int | Sequence[int]): Temporal strides in\n",
    "                residual and conv layers. Default: 1.\n",
    "            dilation (int): Spacing between kernel elements. Default: 1.\n",
    "            style (str): ``pytorch`` or ``caffe``. If set to ``pytorch``,\n",
    "                the stride-two layer is the 3x3 conv layer, otherwise\n",
    "                the stride-two layer is the first 1x1 conv layer.\n",
    "                Default: ``pytorch``.\n",
    "            inflate (int | Sequence[int]): Determine whether to inflate\n",
    "                for each block. Default: 1.\n",
    "            inflate_style (str): ``3x1x1`` or ``3x3x3``. which determines\n",
    "                the kernel sizes and padding strides for conv1 and conv2\n",
    "                in each block. Default: '3x1x1'.\n",
    "            non_local (int | Sequence[int]): Determine whether to apply\n",
    "                non-local module in the corresponding block of each stages.\n",
    "                Default: 0.\n",
    "            non_local_cfg (dict): Config for non-local module.\n",
    "                Default: ``dict()``.\n",
    "            conv_cfg (dict | None): Config for norm layers. Default: None.\n",
    "            norm_cfg (dict | None): Config for norm layers. Default: None.\n",
    "            act_cfg (dict | None): Config for activate layers. Default: None.\n",
    "            with_cp (bool | None): Use checkpoint or not. Using checkpoint\n",
    "                will save some memory while slowing down the training speed.\n",
    "                Default: False.\n",
    "        Returns:\n",
    "            nn.Module: A residual layer for the given config.\n",
    "        \"\"\"\n",
    "        inflate = inflate if not isinstance(inflate, int) else (inflate,) * blocks\n",
    "        non_local = (\n",
    "            non_local if not isinstance(non_local, int) else (non_local,) * blocks\n",
    "        )\n",
    "        assert len(inflate) == blocks and len(non_local) == blocks\n",
    "        downsample = None\n",
    "        if spatial_stride != 1 or inplanes != planes * block.expansion:\n",
    "            downsample = ConvModule(\n",
    "                inplanes,\n",
    "                planes * block.expansion,\n",
    "                kernel_size=1,\n",
    "                stride=(temporal_stride, spatial_stride, spatial_stride),\n",
    "                bias=False,\n",
    "                conv_cfg=conv_cfg,\n",
    "                norm_cfg=norm_cfg,\n",
    "                act_cfg=None,\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(\n",
    "                inplanes,\n",
    "                planes,\n",
    "                spatial_stride=spatial_stride,\n",
    "                temporal_stride=temporal_stride,\n",
    "                dilation=dilation,\n",
    "                downsample=downsample,\n",
    "                style=style,\n",
    "                inflate=(inflate[0] == 1),\n",
    "                inflate_style=inflate_style,\n",
    "                non_local=(non_local[0] == 1),\n",
    "                non_local_cfg=non_local_cfg,\n",
    "                norm_cfg=norm_cfg,\n",
    "                conv_cfg=conv_cfg,\n",
    "                act_cfg=act_cfg,\n",
    "                with_cp=with_cp,\n",
    "                **kwargs,\n",
    "            )\n",
    "        )\n",
    "        inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            block_dpr = drop_path_rate * i / (blocks - 1)\n",
    "            layers.append(\n",
    "                block(\n",
    "                    inplanes,\n",
    "                    planes,\n",
    "                    spatial_stride=1,\n",
    "                    temporal_stride=1,\n",
    "                    dilation=dilation,\n",
    "                    style=style,\n",
    "                    inflate=(inflate[i] == 1),\n",
    "                    inflate_style=inflate_style,\n",
    "                    non_local=(non_local[i] == 1),\n",
    "                    non_local_cfg=non_local_cfg,\n",
    "                    norm_cfg=norm_cfg,\n",
    "                    conv_cfg=conv_cfg,\n",
    "                    act_cfg=act_cfg,\n",
    "                    with_cp=with_cp,\n",
    "                    drop_path=DropPath(block_dpr) if block_dpr > 0.0 else None,\n",
    "                    **kwargs,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    @staticmethod\n",
    "    def _inflate_conv_params(\n",
    "        conv3d, state_dict_2d, module_name_2d, inflated_param_names\n",
    "    ):\n",
    "        \"\"\"Inflate a conv module from 2d to 3d.\n",
    "        Args:\n",
    "            conv3d (nn.Module): The destination conv3d module.\n",
    "            state_dict_2d (OrderedDict): The state dict of pretrained 2d model.\n",
    "            module_name_2d (str): The name of corresponding conv module in the\n",
    "                2d model.\n",
    "            inflated_param_names (list[str]): List of parameters that have been\n",
    "                inflated.\n",
    "        \"\"\"\n",
    "        weight_2d_name = module_name_2d + \".weight\"\n",
    "\n",
    "        conv2d_weight = state_dict_2d[weight_2d_name]\n",
    "        kernel_t = conv3d.weight.data.shape[2]\n",
    "\n",
    "        new_weight = conv2d_weight.data.unsqueeze(2).expand_as(conv3d.weight) / kernel_t\n",
    "        conv3d.weight.data.copy_(new_weight)\n",
    "        inflated_param_names.append(weight_2d_name)\n",
    "\n",
    "        if getattr(conv3d, \"bias\") is not None:\n",
    "            bias_2d_name = module_name_2d + \".bias\"\n",
    "            conv3d.bias.data.copy_(state_dict_2d[bias_2d_name])\n",
    "            inflated_param_names.append(bias_2d_name)\n",
    "\n",
    "    @staticmethod\n",
    "    def _inflate_bn_params(bn3d, state_dict_2d, module_name_2d, inflated_param_names):\n",
    "        \"\"\"Inflate a norm module from 2d to 3d.\n",
    "        Args:\n",
    "            bn3d (nn.Module): The destination bn3d module.\n",
    "            state_dict_2d (OrderedDict): The state dict of pretrained 2d model.\n",
    "            module_name_2d (str): The name of corresponding bn module in the\n",
    "                2d model.\n",
    "            inflated_param_names (list[str]): List of parameters that have been\n",
    "                inflated.\n",
    "        \"\"\"\n",
    "        for param_name, param in bn3d.named_parameters():\n",
    "            param_2d_name = f\"{module_name_2d}.{param_name}\"\n",
    "            param_2d = state_dict_2d[param_2d_name]\n",
    "            if param.data.shape != param_2d.shape:\n",
    "                warnings.warn(\n",
    "                    f\"The parameter of {module_name_2d} is not\"\n",
    "                    \"loaded due to incompatible shapes. \"\n",
    "                )\n",
    "                return\n",
    "\n",
    "            param.data.copy_(param_2d)\n",
    "            inflated_param_names.append(param_2d_name)\n",
    "\n",
    "        for param_name, param in bn3d.named_buffers():\n",
    "            param_2d_name = f\"{module_name_2d}.{param_name}\"\n",
    "            # some buffers like num_batches_tracked may not exist in old\n",
    "            # checkpoints\n",
    "            if param_2d_name in state_dict_2d:\n",
    "                param_2d = state_dict_2d[param_2d_name]\n",
    "                param.data.copy_(param_2d)\n",
    "                inflated_param_names.append(param_2d_name)\n",
    "\n",
    "    @staticmethod\n",
    "    def _inflate_weights(self, logger):\n",
    "        \"\"\"Inflate the resnet2d parameters to resnet3d.\n",
    "        The differences between resnet3d and resnet2d mainly lie in an extra\n",
    "        axis of conv kernel. To utilize the pretrained parameters in 2d model,\n",
    "        the weight of conv2d models should be inflated to fit in the shapes of\n",
    "        the 3d counterpart.\n",
    "        Args:\n",
    "            logger (logging.Logger): The logger used to print\n",
    "                debugging infomation.\n",
    "        \"\"\"\n",
    "\n",
    "        state_dict_r2d = _load_checkpoint(self.pretrained)\n",
    "        if \"state_dict\" in state_dict_r2d:\n",
    "            state_dict_r2d = state_dict_r2d[\"state_dict\"]\n",
    "\n",
    "        inflated_param_names = []\n",
    "        for name, module in self.named_modules():\n",
    "            if isinstance(module, ConvModule):\n",
    "                # we use a ConvModule to wrap conv+bn+relu layers, thus the\n",
    "                # name mapping is needed\n",
    "                if \"downsample\" in name:\n",
    "                    # layer{X}.{Y}.downsample.conv->layer{X}.{Y}.downsample.0\n",
    "                    original_conv_name = name + \".0\"\n",
    "                    # layer{X}.{Y}.downsample.bn->layer{X}.{Y}.downsample.1\n",
    "                    original_bn_name = name + \".1\"\n",
    "                else:\n",
    "                    # layer{X}.{Y}.conv{n}.conv->layer{X}.{Y}.conv{n}\n",
    "                    original_conv_name = name\n",
    "                    # layer{X}.{Y}.conv{n}.bn->layer{X}.{Y}.bn{n}\n",
    "                    original_bn_name = name.replace(\"conv\", \"bn\")\n",
    "                if original_conv_name + \".weight\" not in state_dict_r2d:\n",
    "                    logger.warning(\n",
    "                        f\"Module not exist in the state_dict_r2d\"\n",
    "                        f\": {original_conv_name}\"\n",
    "                    )\n",
    "                else:\n",
    "                    shape_2d = state_dict_r2d[original_conv_name + \".weight\"].shape\n",
    "                    shape_3d = module.conv.weight.data.shape\n",
    "                    if shape_2d != shape_3d[:2] + shape_3d[3:]:\n",
    "                        logger.warning(\n",
    "                            f\"Weight shape mismatch for \"\n",
    "                            f\": {original_conv_name} : \"\n",
    "                            f\"3d weight shape: {shape_3d}; \"\n",
    "                            f\"2d weight shape: {shape_2d}. \"\n",
    "                        )\n",
    "                    else:\n",
    "                        self._inflate_conv_params(\n",
    "                            module.conv,\n",
    "                            state_dict_r2d,\n",
    "                            original_conv_name,\n",
    "                            inflated_param_names,\n",
    "                        )\n",
    "\n",
    "                if original_bn_name + \".weight\" not in state_dict_r2d:\n",
    "                    logger.warning(\n",
    "                        f\"Module not exist in the state_dict_r2d\"\n",
    "                        f\": {original_bn_name}\"\n",
    "                    )\n",
    "                else:\n",
    "                    self._inflate_bn_params(\n",
    "                        module.bn,\n",
    "                        state_dict_r2d,\n",
    "                        original_bn_name,\n",
    "                        inflated_param_names,\n",
    "                    )\n",
    "\n",
    "        # check if any parameters in the 2d checkpoint are not loaded\n",
    "        remaining_names = set(state_dict_r2d.keys()) - set(inflated_param_names)\n",
    "        if remaining_names:\n",
    "            logger.info(\n",
    "                f\"These parameters in the 2d checkpoint are not loaded\"\n",
    "                f\": {remaining_names}\"\n",
    "            )\n",
    "\n",
    "    def inflate_weights(self, logger):\n",
    "        self._inflate_weights(self, logger)\n",
    "\n",
    "    def _make_stem_layer(self):\n",
    "        \"\"\"Construct the stem layers consists of a conv+norm+act module and a\n",
    "        pooling layer.\"\"\"\n",
    "        self.conv1 = ConvModule(\n",
    "            self.in_channels,\n",
    "            self.base_channels,\n",
    "            kernel_size=self.conv1_kernel,\n",
    "            stride=(self.conv1_stride_t, self.conv1_stride_s, self.conv1_stride_s),\n",
    "            padding=tuple([(k - 1) // 2 for k in _triple(self.conv1_kernel)]),\n",
    "            bias=False,\n",
    "            conv_cfg=self.conv_cfg,\n",
    "            norm_cfg=self.norm_cfg,\n",
    "            act_cfg=self.act_cfg,\n",
    "        )\n",
    "\n",
    "        self.maxpool = nn.MaxPool3d(\n",
    "            kernel_size=(1, 3, 3),\n",
    "            stride=(self.pool1_stride_t, self.pool1_stride_s, self.pool1_stride_s),\n",
    "            padding=(0, 1, 1),\n",
    "        )\n",
    "\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1))\n",
    "\n",
    "    def _freeze_stages(self):\n",
    "        \"\"\"Prevent all the parameters from being optimized before\n",
    "        ``self.frozen_stages``.\"\"\"\n",
    "        if self.frozen_stages >= 0:\n",
    "            self.conv1.eval()\n",
    "            for param in self.conv1.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        for i in range(1, self.frozen_stages + 1):\n",
    "            m = getattr(self, f\"layer{i}\")\n",
    "            m.eval()\n",
    "            for param in m.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    @staticmethod\n",
    "    def _init_weights(self, pretrained=None):\n",
    "        \"\"\"Initiate the parameters either from existing checkpoint or from\n",
    "        scratch.\n",
    "        Args:\n",
    "            pretrained (str | None): The path of the pretrained weight. Will\n",
    "                override the original `pretrained` if set. The arg is added to\n",
    "                be compatible with mmdet. Default: None.\n",
    "        \"\"\"\n",
    "        if pretrained:\n",
    "            self.pretrained = pretrained\n",
    "        if isinstance(self.pretrained, str):\n",
    "            logger = logging.Logger()\n",
    "            logger.info(f\"load model from: {self.pretrained}\")\n",
    "\n",
    "            if self.pretrained2d:\n",
    "                # Inflate 2D model into 3D model.\n",
    "                self.inflate_weights(logger)\n",
    "\n",
    "            else:\n",
    "                # Directly load 3D model.\n",
    "                load_checkpoint(self, self.pretrained, strict=False, logger=logger)\n",
    "\n",
    "        elif self.pretrained is None:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Conv3d):\n",
    "                    kaiming_init(m)\n",
    "                elif isinstance(m, _BatchNorm):\n",
    "                    constant_init(m, 1)\n",
    "\n",
    "            if self.zero_init_residual:\n",
    "                for m in self.modules():\n",
    "                    if isinstance(m, Bottleneck3d):\n",
    "                        constant_init(m.conv3.bn, 0)\n",
    "                    elif isinstance(m, BasicBlock3d):\n",
    "                        constant_init(m.conv2.bn, 0)\n",
    "        else:\n",
    "            raise TypeError(\"pretrained must be a str or None\")\n",
    "\n",
    "    def init_weights(self, pretrained=None):\n",
    "        self._init_weights(self, pretrained)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Defines the computation performed at every call.\n",
    "        Args:\n",
    "            x (torch.Tensor): The input data.\n",
    "        Returns:\n",
    "            torch.Tensor: The feature of the input\n",
    "            samples extracted by the backbone.\n",
    "        \"\"\"\n",
    "        x = self.conv1(x)\n",
    "        outs = [x]\n",
    "\n",
    "        if self.with_pool1:\n",
    "            x = self.maxpool(x)\n",
    "        for i, layer_name in enumerate(self.res_layers):\n",
    "            res_layer = getattr(self, layer_name)\n",
    "            x = res_layer(x)\n",
    "            # print(i, x.shape)\n",
    "            if i == 0 and self.with_pool2:\n",
    "                x = self.pool2(x)\n",
    "            if i in self.out_indices:\n",
    "                outs.append(x)\n",
    "        if len(outs) == 1:\n",
    "            return outs[0]\n",
    "\n",
    "        return tuple(outs)\n",
    "\n",
    "    def train(self, mode=True):\n",
    "        \"\"\"Set the optimization status when training.\"\"\"\n",
    "        super().train(mode)\n",
    "        self._freeze_stages()\n",
    "        if mode and self.norm_eval:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, _BatchNorm):\n",
    "                    m.eval()\n",
    "\n",
    "\n",
    "class ResNet3dLayer(nn.Module):\n",
    "    \"\"\"ResNet 3d Layer.\n",
    "    Args:\n",
    "        depth (int): Depth of resnet, from {18, 34, 50, 101, 152}.\n",
    "        pretrained (str | None): Name of pretrained model.\n",
    "        pretrained2d (bool): Whether to load pretrained 2D model.\n",
    "            Default: True.\n",
    "        stage (int): The index of Resnet stage. Default: 3.\n",
    "        base_channels (int): Channel num of stem output features. Default: 64.\n",
    "        spatial_stride (int): The 1st res block's spatial stride. Default 2.\n",
    "        temporal_stride (int): The 1st res block's temporal stride. Default 1.\n",
    "        dilation (int): The dilation. Default: 1.\n",
    "        style (str): `pytorch` or `caffe`. If set to \"pytorch\", the stride-two\n",
    "            layer is the 3x3 conv layer, otherwise the stride-two layer is\n",
    "            the first 1x1 conv layer. Default: 'pytorch'.\n",
    "        all_frozen (bool): Frozen all modules in the layer. Default: False.\n",
    "        inflate (int): Inflate Dims of each block. Default: 1.\n",
    "        inflate_style (str): ``3x1x1`` or ``3x3x3``. which determines the\n",
    "            kernel sizes and padding strides for conv1 and conv2 in each block.\n",
    "            Default: '3x1x1'.\n",
    "        conv_cfg (dict): Config for conv layers. required keys are ``type``\n",
    "            Default: ``dict(type='Conv3d')``.\n",
    "        norm_cfg (dict): Config for norm layers. required keys are ``type`` and\n",
    "            ``requires_grad``.\n",
    "            Default: ``dict(type='BN3d', requires_grad=True)``.\n",
    "        act_cfg (dict): Config dict for activation layer.\n",
    "            Default: ``dict(type='ReLU', inplace=True)``.\n",
    "        norm_eval (bool): Whether to set BN layers to eval mode, namely, freeze\n",
    "            running stats (mean and var). Default: False.\n",
    "        with_cp (bool): Use checkpoint or not. Using checkpoint will save some\n",
    "            memory while slowing down the training speed. Default: False.\n",
    "        zero_init_residual (bool):\n",
    "            Whether to use zero initialization for residual block,\n",
    "            Default: True.\n",
    "        kwargs (dict, optional): Key arguments for \"make_res_layer\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        depth,\n",
    "        pretrained,\n",
    "        pretrained2d=True,\n",
    "        stage=3,\n",
    "        base_channels=64,\n",
    "        spatial_stride=2,\n",
    "        temporal_stride=1,\n",
    "        dilation=1,\n",
    "        style=\"pytorch\",\n",
    "        all_frozen=False,\n",
    "        inflate=1,\n",
    "        inflate_style=\"3x1x1\",\n",
    "        conv_cfg=dict(type=\"Conv3d\"),\n",
    "        norm_cfg=dict(type=\"BN3d\", requires_grad=True),\n",
    "        act_cfg=dict(type=\"ReLU\", inplace=True),\n",
    "        norm_eval=False,\n",
    "        with_cp=False,\n",
    "        zero_init_residual=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.arch_settings = ResNet3d.arch_settings\n",
    "        assert depth in self.arch_settings\n",
    "\n",
    "        self.make_res_layer = ResNet3d.make_res_layer\n",
    "        self._inflate_conv_params = ResNet3d._inflate_conv_params\n",
    "        self._inflate_bn_params = ResNet3d._inflate_bn_params\n",
    "        self._inflate_weights = ResNet3d._inflate_weights\n",
    "        self._init_weights = ResNet3d._init_weights\n",
    "\n",
    "        self.depth = depth\n",
    "        self.pretrained = pretrained\n",
    "        self.pretrained2d = pretrained2d\n",
    "        self.stage = stage\n",
    "        # stage index is 0 based\n",
    "        assert 0 <= stage <= 3\n",
    "        self.base_channels = base_channels\n",
    "\n",
    "        self.spatial_stride = spatial_stride\n",
    "        self.temporal_stride = temporal_stride\n",
    "        self.dilation = dilation\n",
    "\n",
    "        self.style = style\n",
    "        self.all_frozen = all_frozen\n",
    "\n",
    "        self.stage_inflation = inflate\n",
    "        self.inflate_style = inflate_style\n",
    "        self.conv_cfg = conv_cfg\n",
    "        self.norm_cfg = norm_cfg\n",
    "        self.act_cfg = act_cfg\n",
    "        self.norm_eval = norm_eval\n",
    "        self.with_cp = with_cp\n",
    "        self.zero_init_residual = zero_init_residual\n",
    "\n",
    "        block, stage_blocks = self.arch_settings[depth]\n",
    "        stage_block = stage_blocks[stage]\n",
    "        planes = 64 * 2**stage\n",
    "        inplanes = 64 * 2 ** (stage - 1) * block.expansion\n",
    "\n",
    "        res_layer = self.make_res_layer(\n",
    "            block,\n",
    "            inplanes,\n",
    "            planes,\n",
    "            stage_block,\n",
    "            spatial_stride=spatial_stride,\n",
    "            temporal_stride=temporal_stride,\n",
    "            dilation=dilation,\n",
    "            style=self.style,\n",
    "            norm_cfg=self.norm_cfg,\n",
    "            conv_cfg=self.conv_cfg,\n",
    "            act_cfg=self.act_cfg,\n",
    "            inflate=self.stage_inflation,\n",
    "            inflate_style=self.inflate_style,\n",
    "            with_cp=with_cp,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "        self.layer_name = f\"layer{stage + 1}\"\n",
    "        self.add_module(self.layer_name, res_layer)\n",
    "\n",
    "    def inflate_weights(self, logger):\n",
    "        self._inflate_weights(self, logger)\n",
    "\n",
    "    def _freeze_stages(self):\n",
    "        \"\"\"Prevent all the parameters from being optimized before\n",
    "        ``self.frozen_stages``.\"\"\"\n",
    "        if self.all_frozen:\n",
    "            layer = getattr(self, self.layer_name)\n",
    "            layer.eval()\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def init_weights(self, pretrained=None):\n",
    "        self._init_weights(self, pretrained)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Defines the computation performed at every call.\n",
    "        Args:\n",
    "            x (torch.Tensor): The input data.\n",
    "        Returns:\n",
    "            torch.Tensor: The feature of the input\n",
    "            samples extracted by the backbone.\n",
    "        \"\"\"\n",
    "        res_layer = getattr(self, self.layer_name)\n",
    "        out = res_layer(x)\n",
    "        return out\n",
    "\n",
    "    def train(self, mode=True):\n",
    "        \"\"\"Set the optimization status when training.\"\"\"\n",
    "        super().train(mode)\n",
    "        self._freeze_stages()\n",
    "        if mode and self.norm_eval:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, _BatchNorm):\n",
    "                    m.eval()\n",
    "\n",
    "\n",
    "class CSNBottleneck3d(Bottleneck3d):\n",
    "    \"\"\"Channel-Separated Bottleneck Block.\n",
    "    This module is proposed in\n",
    "    \"Video Classification with Channel-Separated Convolutional Networks\"\n",
    "    Link: https://arxiv.org/pdf/1711.11248.pdf\n",
    "    Args:\n",
    "        inplanes (int): Number of channels for the input in first conv3d layer.\n",
    "        planes (int): Number of channels produced by some norm/conv3d layers.\n",
    "        bottleneck_mode (str): Determine which ways to factorize a 3D\n",
    "            bottleneck block using channel-separated convolutional networks.\n",
    "                If set to 'ip', it will replace the 3x3x3 conv2 layer with a\n",
    "                1x1x1 traditional convolution and a 3x3x3 depthwise\n",
    "                convolution, i.e., Interaction-preserved channel-separated\n",
    "                bottleneck block.\n",
    "                If set to 'ir', it will replace the 3x3x3 conv2 layer with a\n",
    "                3x3x3 depthwise convolution, which is derived from preserved\n",
    "                bottleneck block by removing the extra 1x1x1 convolution,\n",
    "                i.e., Interaction-reduced channel-separated bottleneck block.\n",
    "            Default: 'ir'.\n",
    "        args (position arguments): Position arguments for Bottleneck.\n",
    "        kwargs (dict, optional): Keyword arguments for Bottleneck.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, inplanes, planes, *args, bottleneck_mode=\"ir\", **kwargs):\n",
    "        super(CSNBottleneck3d, self).__init__(inplanes, planes, *args, **kwargs)\n",
    "        self.bottleneck_mode = bottleneck_mode\n",
    "        conv2 = []\n",
    "        if self.bottleneck_mode == \"ip\":\n",
    "            conv2.append(\n",
    "                ConvModule(\n",
    "                    planes,\n",
    "                    planes,\n",
    "                    1,\n",
    "                    stride=1,\n",
    "                    bias=False,\n",
    "                    conv_cfg=self.conv_cfg,\n",
    "                    norm_cfg=self.norm_cfg,\n",
    "                    act_cfg=None,\n",
    "                )\n",
    "            )\n",
    "        conv2_kernel_size = self.conv2.conv.kernel_size\n",
    "        conv2_stride = self.conv2.conv.stride\n",
    "        conv2_padding = self.conv2.conv.padding\n",
    "        conv2_dilation = self.conv2.conv.dilation\n",
    "        conv2_bias = bool(self.conv2.conv.bias)\n",
    "        self.conv2 = ConvModule(\n",
    "            planes,\n",
    "            planes,\n",
    "            conv2_kernel_size,\n",
    "            stride=conv2_stride,\n",
    "            padding=conv2_padding,\n",
    "            dilation=conv2_dilation,\n",
    "            bias=conv2_bias,\n",
    "            conv_cfg=self.conv_cfg,\n",
    "            norm_cfg=self.norm_cfg,\n",
    "            act_cfg=self.act_cfg,\n",
    "            groups=planes,\n",
    "        )\n",
    "        conv2.append(self.conv2)\n",
    "        self.conv2 = nn.Sequential(*conv2)\n",
    "\n",
    "\n",
    "class ResNet3dCSN(ResNet3d):\n",
    "    \"\"\"ResNet backbone for CSN.\n",
    "    Args:\n",
    "        depth (int): Depth of ResNetCSN, from {18, 34, 50, 101, 152}.\n",
    "        pretrained (str | None): Name of pretrained model.\n",
    "        temporal_strides (tuple[int]):\n",
    "            Temporal strides of residual blocks of each stage.\n",
    "            Default: (1, 2, 2, 2).\n",
    "        conv1_kernel (tuple[int]): Kernel size of the first conv layer.\n",
    "            Default: (3, 7, 7).\n",
    "        conv1_stride_t (int): Temporal stride of the first conv layer.\n",
    "            Default: 1.\n",
    "        pool1_stride_t (int): Temporal stride of the first pooling layer.\n",
    "            Default: 1.\n",
    "        norm_cfg (dict): Config for norm layers. required keys are `type` and\n",
    "            `requires_grad`.\n",
    "            Default: dict(type='BN3d', requires_grad=True, eps=1e-3).\n",
    "        inflate_style (str): `3x1x1` or `3x3x3`. which determines the kernel\n",
    "            sizes and padding strides for conv1 and conv2 in each block.\n",
    "            Default: '3x3x3'.\n",
    "        bottleneck_mode (str): Determine which ways to factorize a 3D\n",
    "            bottleneck block using channel-separated convolutional networks.\n",
    "                If set to 'ip', it will replace the 3x3x3 conv2 layer with a\n",
    "                1x1x1 traditional convolution and a 3x3x3 depthwise\n",
    "                convolution, i.e., Interaction-preserved channel-separated\n",
    "                bottleneck block.\n",
    "                If set to 'ir', it will replace the 3x3x3 conv2 layer with a\n",
    "                3x3x3 depthwise convolution, which is derived from preserved\n",
    "                bottleneck block by removing the extra 1x1x1 convolution,\n",
    "                i.e., Interaction-reduced channel-separated bottleneck block.\n",
    "            Default: 'ip'.\n",
    "        kwargs (dict, optional): Key arguments for \"make_res_layer\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        depth,\n",
    "        pretrained,\n",
    "        temporal_strides=(1, 2, 2, 2),\n",
    "        conv1_kernel=(3, 7, 7),\n",
    "        conv1_stride_t=1,\n",
    "        pool1_stride_t=1,\n",
    "        norm_cfg=dict(type=\"BN3d\", requires_grad=True, eps=1e-3),\n",
    "        inflate_style=\"3x3x3\",\n",
    "        bottleneck_mode=\"ir\",\n",
    "        bn_frozen=False,\n",
    "        drop_path_rate=0.0,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.arch_settings = {\n",
    "            # 18: (BasicBlock3d, (2, 2, 2, 2)),\n",
    "            # 34: (BasicBlock3d, (3, 4, 6, 3)),\n",
    "            50: (CSNBottleneck3d, (3, 4, 6, 3)),\n",
    "            101: (CSNBottleneck3d, (3, 4, 23, 3)),\n",
    "            152: (CSNBottleneck3d, (3, 8, 36, 3)),\n",
    "        }\n",
    "        self.bn_frozen = bn_frozen\n",
    "        if bottleneck_mode not in [\"ip\", \"ir\"]:\n",
    "            raise ValueError(\n",
    "                f'Bottleneck mode must be \"ip\" or \"ir\",' f\"but got {bottleneck_mode}.\"\n",
    "            )\n",
    "        super(ResNet3dCSN, self).__init__(\n",
    "            depth,\n",
    "            pretrained,\n",
    "            temporal_strides=temporal_strides,\n",
    "            conv1_kernel=conv1_kernel,\n",
    "            conv1_stride_t=conv1_stride_t,\n",
    "            pool1_stride_t=pool1_stride_t,\n",
    "            norm_cfg=norm_cfg,\n",
    "            inflate_style=inflate_style,\n",
    "            bottleneck_mode=bottleneck_mode,\n",
    "            drop_path_rate=drop_path_rate,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def train(self, mode=True):\n",
    "        super(ResNet3d, self).train(mode)\n",
    "        self._freeze_stages()\n",
    "        if mode and self.norm_eval:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, _BatchNorm):\n",
    "                    m.eval()\n",
    "                    if self.bn_frozen:\n",
    "                        for param in m.parameters():\n",
    "                            param.requires_grad = False\n",
    "\n",
    "                            \n",
    "                            \n",
    "class InkDetResNet3dCSNModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        pretrained: bool = False,\n",
    "        depth: str = \"50\",\n",
    "        bottleneck_mode: str = \"ir\",\n",
    "        drop_path_rate: float = 0.0,\n",
    "        in_chans: int = 1,\n",
    "        preprocess_in_model: bool = False,\n",
    "        start_z: int = 8,\n",
    "        end_z: int = -8,\n",
    "        shift_z: int = 2,\n",
    "        sampling_z: int = 1,\n",
    "        num_class: int = 1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.backbone = ResNet3dCSN(\n",
    "            pretrained2d=False,\n",
    "            in_channels=in_chans,\n",
    "            pretrained=None,\n",
    "            depth=int(depth),\n",
    "            with_pool2=False,\n",
    "            bottleneck_mode=bottleneck_mode,\n",
    "            norm_eval=False,\n",
    "            zero_init_residual=False,\n",
    "            drop_path_rate=drop_path_rate,\n",
    "        )\n",
    "        self.in_chans = in_chans\n",
    "        self.head = nn.Sequential(\n",
    "            nn.BatchNorm2d(2048),\n",
    "            nn.Conv2d(\n",
    "                2048,\n",
    "                512,\n",
    "                1,\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.Conv2d(\n",
    "                512,\n",
    "                num_class,\n",
    "                1,\n",
    "            ),\n",
    "        )\n",
    "        self.preprocess_in_model = preprocess_in_model\n",
    "        self.start_z = start_z\n",
    "        self.end_z = end_z\n",
    "        self.shift_z = shift_z\n",
    "        self.sampling_z = sampling_z\n",
    "        if pretrained:\n",
    "            load_weights = {\n",
    "                \"50\": {\n",
    "                    \"ir\": \"../../libs/pretrained/vmz_ircsn_ig65m_pretrained_r50_32x2x1_58e_kinetics400_rgb_20210617-86d33018.pth\"\n",
    "                },\n",
    "                \"152\": {\n",
    "                    \"ir\": \"../../libs/pretrained/ircsn_ig65m-pretrained-r152_8xb12-32x2x1-58e_kinetics400-rgb_20220811-c7a3cc5b.pth\"\n",
    "                },\n",
    "            }\n",
    "            load_weight = load_weights[depth][bottleneck_mode]\n",
    "            rank_zero_info(f\"load pretrained weight {load_weight}!!!\")\n",
    "            state_dict = torch.load(load_weight, map_location=\"cpu\")  # load checkpoint\n",
    "            if \"state_dict\" in state_dict.keys():\n",
    "                state_dict = state_dict[\"state_dict\"]\n",
    "            state_dict = intersect_dicts(\n",
    "                state_dict, self.state_dict(), exclude=[]\n",
    "            )  # intersect\n",
    "            self.load_state_dict(state_dict, strict=False)  # load\n",
    "            print(\n",
    "                \"Transferred %g/%g items from %s\"\n",
    "                % (len(state_dict), len(self.state_dict()), load_weight)\n",
    "            )  # report\n",
    "            del state_dict\n",
    "            gc.collect()\n",
    "\n",
    "    def preprocess(self, img):\n",
    "        if self.training and np.random.rand() < 0.5:\n",
    "            shift = np.random.randint(-self.shift_z, self.shift_z + 1)\n",
    "        else:\n",
    "            shift = 0\n",
    "        img = img[:, self.start_z + shift : self.end_z + shift]\n",
    "        img = img[:: self.sampling_z]\n",
    "        return img\n",
    "\n",
    "    def forward_image_feats(self, img):\n",
    "        if self.preprocess_in_model:\n",
    "            img = self.preprocess(img)\n",
    "        mean = img.mean(dim=(1, 2, 3), keepdim=True)\n",
    "        std = img.std(dim=(1, 2, 3), keepdim=True) + 1e-6\n",
    "        img = (img - mean) / std\n",
    "        bs, ch, h, w = img.shape\n",
    "        assert ch % self.in_chans == 0\n",
    "        groups_3d = ch // self.in_chans\n",
    "        img = img.reshape((bs, groups_3d, self.in_chans, h, w))\n",
    "\n",
    "        if self.training:\n",
    "            ch_arr = list(range(img.shape[2]))\n",
    "            ch_arr = [\n",
    "                random.sample(ch_arr, len(ch_arr)) if np.random.rand() < 0.2 else ch_arr\n",
    "                for _ in range(img.shape[0])\n",
    "            ]\n",
    "            for i, ca in enumerate(ch_arr):\n",
    "                img[i] = img[i, :, ca]\n",
    "        img = img.permute(0, 2, 1, 3, 4).contiguous()\n",
    "        img_feat = self.backbone(img)[-1].amax(2)\n",
    "        return img_feat\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        img: torch.Tensor,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        img: (bs, ch, h, w)\n",
    "        \"\"\"\n",
    "        img_feat = self.forward_image_feats(img)\n",
    "        return self.head(img_feat)\n",
    "    \n",
    "    \n",
    "                            \n",
    "class InkDetLightningModel3d(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        valid_fragment_id: str,\n",
    "        pretrained: bool = False,\n",
    "        depth: str = \"50\",\n",
    "        bottleneck_mode: str = \"ir\",\n",
    "        drop_path_rate: float = 0.0,\n",
    "        in_chans: int = 1,\n",
    "        preprocess_in_model: bool = False,\n",
    "        start_z: int = 8,\n",
    "        end_z: int = -8,\n",
    "        sampling_z: int = 1,\n",
    "        shift_z: int = 2,\n",
    "        mixup_p: float = 0.0,\n",
    "        mixup_alpha: float = 0.5,\n",
    "        no_mixup_epochs: int = 0,\n",
    "        lr: float = 1e-3,\n",
    "        backbone_lr: float = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.__build_model(\n",
    "            pretrained=pretrained,\n",
    "            depth=depth,\n",
    "            bottleneck_mode=bottleneck_mode,\n",
    "            drop_path_rate=drop_path_rate,\n",
    "            in_chans=in_chans,\n",
    "            preprocess_in_model=preprocess_in_model,\n",
    "            start_z=start_z,\n",
    "            end_z=end_z,\n",
    "            sampling_z=sampling_z,\n",
    "            shift_z=shift_z,\n",
    "        )\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def __build_model(\n",
    "        self,\n",
    "        pretrained: bool = False,\n",
    "        depth: str = \"50\",\n",
    "        bottleneck_mode: str = \"ir\",\n",
    "        drop_path_rate: float = 0.0,\n",
    "        in_chans: int = 1,\n",
    "        preprocess_in_model: bool = False,\n",
    "        start_z: int = 8,\n",
    "        end_z: int = -8,\n",
    "        sampling_z: int = 1,\n",
    "        shift_z: int = 2,\n",
    "    ):\n",
    "        self.model = InkDetResNet3dCSNModel(\n",
    "            pretrained=pretrained,\n",
    "            depth=depth,\n",
    "            bottleneck_mode=bottleneck_mode,\n",
    "            drop_path_rate=drop_path_rate,\n",
    "            in_chans=in_chans,\n",
    "            preprocess_in_model=preprocess_in_model,\n",
    "            start_z=start_z,\n",
    "            end_z=end_z,\n",
    "            sampling_z=sampling_z,\n",
    "            shift_z=shift_z,\n",
    "            num_class=1,\n",
    "        )\n",
    "        self.model_ema = ModelEmaV2(self.model, decay=0.99)\n",
    "        \n",
    "    def predict(self, volume):\n",
    "        output = torch.sigmoid(self.model_ema.module(volume))\n",
    "        output = F.interpolate(\n",
    "            output.float(),\n",
    "            scale_factor=32,\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=True,\n",
    "        ).half()\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d100f1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T05:22:37.641429Z",
     "iopub.status.busy": "2023-08-12T05:22:37.641032Z",
     "iopub.status.idle": "2023-08-12T07:45:06.700621Z",
     "shell.execute_reply": "2023-08-12T07:45:06.699028Z"
    },
    "papermill": {
     "duration": 8549.076599,
     "end_time": "2023-08-12T07:45:06.704394",
     "exception": false,
     "start_time": "2023-08-12T05:22:37.627795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt_path = ['/kaggle/input/vesuvius-weights/vesuvius-weights/train_patch_based/convnext_tiny_split3d3x9csn_l6_mixup_ep30/fold0/vesuvius-challenge-ink-detection/jwvl7ub5/checkpoints/best_fbeta.ckpt', '/kaggle/input/vesuvius-weights/vesuvius-weights/train_patch_based/convnext_tiny_split3d5x7csn_mixup_ep30/fold0/vesuvius-challenge-ink-detection/30k522md/checkpoints/best_fbeta.ckpt', '/kaggle/input/vesuvius-weights/vesuvius-weights/train_patch_based/resnetrs50_split3d3x9csn_l6_mixup_ep30/fold0/vesuvius-challenge-ink-detection/9scixyux/checkpoints/best_fbeta.ckpt', '/kaggle/input/vesuvius-weights/vesuvius-weights/train_patch_based/swinv2_tiny_window8_256_split3d3x9csn_l6_mixup_ep30/fold0/vesuvius-challenge-ink-detection/vjes3z4y/checkpoints/best_fbeta.ckpt', '/kaggle/input/vesuvius-weights/vesuvius-weights/train_patch_based/swinv2_tiny_window8_256_split3d5x7csn_mixup_ep30/fold0/vesuvius-challenge-ink-detection/62p52y7i/checkpoints/best_fbeta.ckpt', '/kaggle/input/vesuvius-weights/vesuvius-weights/train_patch_based_1/resnet3d50csnir1x32_mixup_ep30/fold0/vesuvius-challenge-ink-detection/iap549lk/checkpoints/best_fbeta.ckpt', '/kaggle/input/vesuvius-weights/vesuvius-weights/train_patch_based_1/resnet3d152csnir1x24_mixup_ep30/fold0/vesuvius-challenge-ink-detection/e6m38tyj/checkpoints/best_fbeta.ckpt', '/kaggle/input/vesuvius-weights/vesuvius-weights/train_patch_based_1/resnet3d50csnir1x32_mixup_ep30/fold1/vesuvius-challenge-ink-detection/yxm9hjsu/checkpoints/best_fbeta.ckpt', '/kaggle/input/vesuvius-weights/vesuvius-weights/train_patch_based_1/resnet3d152csnir1x24_mixup_ep30/fold1/vesuvius-challenge-ink-detection/rpyuj1n1/checkpoints/best_fbeta.ckpt']\n",
      "a\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3333822df7684333a5af249b32bb5ed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1802 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(64, 37.50296508323818), (64, 37.50296508323818), (64, 37.50296508323818), (64, 37.50296508323818), (64, 37.50296508323818), (36, 21.130733968604865), (36, 21.130733968604865), (36, 21.130733968604865), (36, 21.130733968604865)] [(0.9697, 0.1437), (0.9683, 0.124), (0.979, 0.1392), (0.97, 0.1675), (0.9653, 0.1404), (0.9746, 0.11945), (0.9746, 0.1273), (0.973, 0.12384), (0.973, 0.11725)]\n",
      "b\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d3b7d01a85424f95bce2db801b5f06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3052 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(64, 32.13583479464324), (64, 32.13583479464324), (64, 32.13583479464324), (64, 32.13583479464324), (64, 32.13583479464324), (36, 18.094502867874994), (36, 18.094502867874994), (36, 18.094502867874994), (36, 18.094502867874994)] [(0.975, 0.1268), (0.969, 0.11646), (0.9854, 0.1109), (0.9697, 0.1316), (0.9663, 0.1272), (0.9785, 0.103), (0.9746, 0.10254), (0.981, 0.1276), (0.973, 0.134)]\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    \"seed\": 2023,\n",
    "    \"image_size\": 256,\n",
    "    \"num_workers\": 2,\n",
    "    \"batch_size\":6,#8\n",
    "    \"models_conf\":\n",
    "    {   #fold0\n",
    "        \"/kaggle/input/vesuvius-weights/vesuvius-weights/train_patch_based/convnext_tiny_split3d3x9csn_l6_mixup_ep30/fold0\": {\"infer_size\": 256, \"model\": InkDetLightningModel},\n",
    "        \"/kaggle/input/vesuvius-weights/vesuvius-weights/train_patch_based/convnext_tiny_split3d5x7csn_mixup_ep30/fold0\": {\"infer_size\": 256, \"model\": InkDetLightningModel},\n",
    "        \"/kaggle/input/vesuvius-weights/vesuvius-weights/train_patch_based/resnetrs50_split3d3x9csn_l6_mixup_ep30/fold0\": {\"infer_size\": 256, \"model\": InkDetLightningModel},\n",
    "        \"/kaggle/input/vesuvius-weights/vesuvius-weights/train_patch_based/swinv2_tiny_window8_256_split3d3x9csn_l6_mixup_ep30/fold0\": {\"infer_size\": 256, \"model\": InkDetLightningModel},\n",
    "        \"/kaggle/input/vesuvius-weights/vesuvius-weights/train_patch_based/swinv2_tiny_window8_256_split3d5x7csn_mixup_ep30/fold0\": {\"infer_size\": 256, \"model\": InkDetLightningModel},\n",
    "        \"/kaggle/input/vesuvius-weights/vesuvius-weights/train_patch_based_1/resnet3d50csnir1x32_mixup_ep30/fold0\": {\"infer_size\": 192, \"model\": InkDetLightningModel3d},\n",
    "        \"/kaggle/input/vesuvius-weights/vesuvius-weights/train_patch_based_1/resnet3d152csnir1x24_mixup_ep30/fold0\": {\"infer_size\": 192, \"model\": InkDetLightningModel3d},\n",
    "        \n",
    "        \"/kaggle/input/vesuvius-weights/vesuvius-weights/train_patch_based_1/resnet3d50csnir1x32_mixup_ep30/fold1\": {\"infer_size\": 192, \"model\": InkDetLightningModel3d},\n",
    "        \"/kaggle/input/vesuvius-weights/vesuvius-weights/train_patch_based_1/resnet3d152csnir1x24_mixup_ep30/fold1\": {\"infer_size\": 192, \"model\": InkDetLightningModel3d},\n",
    "    },\n",
    "    \"threshold\": 0.93,\n",
    "}\n",
    "pl.seed_everything(args[\"seed\"])\n",
    "warnings.simplefilter(\"ignore\")\n",
    "preds = []\n",
    "\n",
    "models_conf = args[\"models_conf\"]\n",
    "ckpt_paths = [glob(f\"{logdir}/**/best_fbeta.ckpt\",recursive=True)[0] for logdir in models_conf]\n",
    "print(f\"ckpt_path = {ckpt_paths}\")\n",
    "models = [models_conf[logdir][\"model\"].load_from_checkpoint(\n",
    "    glob(f\"{logdir}/**/best_fbeta.ckpt\",recursive=True)[0], valid_fragment_id=fragment_ids[0], pretrained=False, preprocess_in_model=True,\n",
    ").half().eval().to(device=device) for logdir in models_conf]\n",
    "\n",
    "\n",
    "def inference_single(model, volume, infer_size, img_size):\n",
    "    pad = (img_size - infer_size) // 2\n",
    "    if pad > 0:\n",
    "        new_volume = volume[..., pad:-pad, pad:-pad]\n",
    "    else:\n",
    "        new_volume = volume\n",
    "    output = model.predict(new_volume)\n",
    "    new_output = torch.zeros((output.shape[0], output.shape[1], output.shape[2] + pad * 2, output.shape[2] + pad * 2)).to(device)\n",
    "    \n",
    "    if pad > 0:\n",
    "        new_output[..., pad:-pad, pad:-pad] = output\n",
    "        mask = torch.zeros((output.shape[0], output.shape[1], output.shape[2] + pad * 2, output.shape[2] + pad * 2)).to(device)\n",
    "        mask[..., pad:-pad, pad:-pad] = torch.ones_like(output)\n",
    "    else:\n",
    "        new_output = output\n",
    "        mask = torch.ones((output.shape[0], output.shape[1], output.shape[2] + pad * 2, output.shape[2] + pad * 2)).to(device)\n",
    "    return new_output, mask\n",
    "\n",
    "def inference(fragment_id):\n",
    "    valid_volume_paths = np.asarray(\n",
    "                    sorted(\n",
    "                        glob(\n",
    "                            f\"vesuvius_patches_{PATCH_SIZE}/test/{fragment_id}/surface_volume/**/*.npy\",\n",
    "                            recursive=True,\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "    \n",
    "    dataloader = InkDetDataModule(\n",
    "        train_volume_paths=valid_volume_paths,\n",
    "        valid_volume_paths=valid_volume_paths,\n",
    "        image_size=args[\"image_size\"],\n",
    "        num_workers=args[\"num_workers\"],\n",
    "        batch_size=args[\"batch_size\"],\n",
    "        preprocess_in_model=True,\n",
    "    ).test_dataloader()\n",
    "    \n",
    "    fragment_mask = np.array(\n",
    "        Image.open(\n",
    "            f\"/kaggle/input/vesuvius-challenge-ink-detection/test/{fragment_id}/mask.png\"\n",
    "        ).convert(\"1\")\n",
    "    ) > 0\n",
    "    \n",
    "    p_valid = np.stack([np.zeros_like(fragment_mask, dtype=np.float16) for _ in models]) # (models, 1, h, w)\n",
    "    count_pix = np.stack([np.zeros_like(fragment_mask, dtype=np.uint8) for _ in models]) # (models, 1, h, w)\n",
    "    count = 0\n",
    "    for batch in tqdm(dataloader):\n",
    "        volume_cpu, _, x, y = batch # volume_cpu: (bs, ch, h, w)\n",
    "        tta_ops = (np.arange(len(volume_cpu)) + count) % 4\n",
    "        count += len(volume_cpu)\n",
    "        for i, j in zip(range(len(volume_cpu)), tta_ops):\n",
    "            if j == 1:\n",
    "                volume_cpu[i] = volume_cpu[i].flip(1)\n",
    "            elif j == 2:\n",
    "                volume_cpu[i] = volume_cpu[i].flip(2)\n",
    "            elif j == 3:\n",
    "                volume_cpu[i] = volume_cpu[i].flip(1).flip(2)\n",
    "        volume = volume_cpu.to(device)\n",
    "        with torch.no_grad():\n",
    "            pred_batch = []\n",
    "            mask_batch = []\n",
    "            for model, logdir in zip(models, models_conf):\n",
    "                pred_batch_single, mask_batch_single = inference_single(model, volume, models_conf[logdir][\"infer_size\"], args[\"image_size\"])\n",
    "                pred_batch.append(pred_batch_single)\n",
    "                mask_batch.append(mask_batch_single)\n",
    "            pred_batch = torch.stack(pred_batch).permute((1, 0, 2, 3, 4)) # (models, bs, 1, h, w) -> (bs, models, 1, h, w)\n",
    "            mask_batch = torch.stack(mask_batch).permute((1, 0, 2, 3, 4)) # (models, bs, 1, h, w) -> (bs, models, 1, h, w)\n",
    "        for i, j in zip(range(len(pred_batch)), tta_ops): # pred_batch: (bs, models, ch, h, w)\n",
    "            if j == 1:\n",
    "                pred_batch[i] = pred_batch[i].flip(2)\n",
    "            elif j == 2:\n",
    "                pred_batch[i] = pred_batch[i].flip(3)\n",
    "            elif j == 3:\n",
    "                pred_batch[i] = pred_batch[i].flip(2).flip(3)\n",
    "        for xi, yi, pi, mi in zip(\n",
    "            x,\n",
    "            y,\n",
    "            pred_batch,\n",
    "            mask_batch,\n",
    "        ):\n",
    "            patch = pi.to(torch.float16).detach().cpu().numpy()\n",
    "            mask = mi.to(torch.uint8).cpu().numpy()\n",
    "            y_lim, x_lim = fragment_mask[..., \n",
    "                yi * PATCH_SIZE : yi * PATCH_SIZE + volume.shape[-2],\n",
    "                xi * PATCH_SIZE : xi * PATCH_SIZE + volume.shape[-1],\n",
    "            ].shape\n",
    "            p_valid[..., \n",
    "                yi * PATCH_SIZE : yi * PATCH_SIZE + volume.shape[-2],\n",
    "                xi * PATCH_SIZE : xi * PATCH_SIZE + volume.shape[-1],\n",
    "            ] += patch[..., 0, :y_lim, :x_lim]\n",
    "            count_pix[..., \n",
    "                yi * PATCH_SIZE : yi * PATCH_SIZE + volume.shape[-2],\n",
    "                xi * PATCH_SIZE : xi * PATCH_SIZE + volume.shape[-1],\n",
    "            ] += mask[..., 0, :y_lim, :x_lim]\n",
    "        del volume_cpu, pred_batch, mask_batch, volume\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    count_pix *= fragment_mask[None, ...]\n",
    "    p_valid /= count_pix\n",
    "    p_valid = np.stack([np.nan_to_num(p, posinf=0, neginf=0) for p in p_valid])\n",
    "    p_valid *= fragment_mask[None, ...]\n",
    "    print([(c.max(), c.mean()) for c in count_pix], [(p.max(), p.mean()) for p in p_valid])\n",
    "    count_pix = count_pix.mean(0) > 0\n",
    "    p_valid = p_valid.mean(0)\n",
    "    p_valid_tmp = p_valid.reshape(-1)[np.where(count_pix.reshape(-1))]\n",
    "    p_valid = p_valid > np.quantile(p_valid_tmp, args[\"threshold\"])\n",
    "    del dataloader, fragment_mask, count_pix, p_valid_tmp\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return p_valid\n",
    "\n",
    "for valid_idx in fragment_ids:\n",
    "    print(valid_idx)\n",
    "    preds.append(inference(valid_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6110ec74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T07:45:06.777924Z",
     "iopub.status.busy": "2023-08-12T07:45:06.776863Z",
     "iopub.status.idle": "2023-08-12T07:45:06.798955Z",
     "shell.execute_reply": "2023-08-12T07:45:06.797844Z"
    },
    "papermill": {
     "duration": 0.056036,
     "end_time": "2023-08-12T07:45:06.801966",
     "exception": false,
     "start_time": "2023-08-12T07:45:06.745930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rle(output):\n",
    "    flat_img = output.astype(np.uint8).flatten()\n",
    "    starts = np.array((flat_img[:-1] == 0) & (flat_img[1:] == 1))\n",
    "    ends = np.array((flat_img[:-1] == 1) & (flat_img[1:] == 0))\n",
    "    starts_ix = np.where(starts)[0] + 2\n",
    "    ends_ix = np.where(ends)[0] + 2\n",
    "    lengths = ends_ix - starts_ix\n",
    "    return \" \".join(map(str, sum(zip(starts_ix, lengths), ())))\n",
    "\n",
    "def fast_rle(img):\n",
    "    flat_img = img.flatten().astype(np.uint8)\n",
    "\n",
    "    starts = np.array((flat_img[:-1] == 0) & (flat_img[1:] == 1))\n",
    "    ends = np.array((flat_img[:-1] == 1) & (flat_img[1:] == 0))\n",
    "    starts_ix = np.where(starts)[0] + 2\n",
    "    ends_ix = np.where(ends)[0] + 2\n",
    "    lengths = ends_ix - starts_ix\n",
    "    predicted_arr = np.stack([starts_ix, lengths]).T.flatten()\n",
    "    f = StringIO()\n",
    "    \n",
    "    # numpy.savetxt(fname, X, fmt='%.18e', delimiter=' ', ) => save an array to a text file.\n",
    "    # fname => filename or file handle\n",
    "    np.savetxt(f, predicted_arr.reshape(1, -1), delimiter=\" \", fmt=\"%d\")\n",
    "    \n",
    "    # .getvalue() => retrieve the entire contents of the “file” at any time before the StringIO object’s close() method is called.\n",
    "    predicted = f.getvalue().strip()\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b42b3caa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T07:45:06.828819Z",
     "iopub.status.busy": "2023-08-12T07:45:06.828495Z",
     "iopub.status.idle": "2023-08-12T07:45:10.027350Z",
     "shell.execute_reply": "2023-08-12T07:45:10.026230Z"
    },
    "papermill": {
     "duration": 3.213545,
     "end_time": "2023-08-12T07:45:10.029687",
     "exception": false,
     "start_time": "2023-08-12T07:45:06.816142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>2807806 15 2814120 41 2820444 54 2826770 59 28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>203945 33 210275 34 216604 35 222933 37 229263...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Id                                          Predicted\n",
       "0  a  2807806 15 2814120 41 2820444 54 2826770 59 28...\n",
       "1  b  203945 33 210275 34 216604 35 222933 37 229263..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "submission = defaultdict(list)\n",
    "# for fragment_id, fragment_name in enumerate(test_fragments):\n",
    "for fragment_id, pred_image in zip(fragment_ids, preds):\n",
    "    plt.imshow(pred_image)\n",
    "    plt.show()\n",
    "    submission[\"Id\"].append(fragment_id)\n",
    "    submission[\"Predicted\"].append(fast_rle(pred_image))\n",
    "\n",
    "pd.DataFrame.from_dict(submission).to_csv(\"/kaggle/working/submission.csv\", index=False)\n",
    "pd.DataFrame.from_dict(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0922aad5",
   "metadata": {
    "papermill": {
     "duration": 0.012329,
     "end_time": "2023-08-12T07:45:10.055015",
     "exception": false,
     "start_time": "2023-08-12T07:45:10.042686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6131745c",
   "metadata": {
    "papermill": {
     "duration": 0.012247,
     "end_time": "2023-08-12T07:45:10.079721",
     "exception": false,
     "start_time": "2023-08-12T07:45:10.067474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8976.773041,
   "end_time": "2023-08-12T07:45:13.042594",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-12T05:15:36.269553",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0d8ba9c424d140b39162ddbbfec88e3b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c8c242d755894f9283b1cd77ded43359",
       "max": 170.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b9ca6b22e42d4d9ebf6069edafbf301c",
       "value": 170.0
      }
     },
     "0f0649784c0b41a19ba6e6f1ae7c8aff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "111587e80bfe4036ac53917b5c9165c4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "14adf033fcd44e128f02f5e4504ab75a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8eff4538bc544998ab2f6df56fac7b1a",
        "IPY_MODEL_f0616dd374dd4ddf83488c046958d696",
        "IPY_MODEL_e4a81a3628e645f6854f4c9591d6a606"
       ],
       "layout": "IPY_MODEL_a9f18f06ec0f4050b432a47fd196e4ee"
      }
     },
     "166d023939f342688d25044b6c69742c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1838dac72efe42dfaf3d456c584e0e55": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2198aeee23d54d58af916e6225c1d08f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2580cd7700fb4364b7f73e5a69c858ac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "27e3a5c4f2444ec2ab953b645498e8fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_acf0147cccf944d9900092d00a9e0cdb",
        "IPY_MODEL_d544d824f1af4365b74681416d6e0a3e",
        "IPY_MODEL_f388eb20501640c0a333120fc21ca707"
       ],
       "layout": "IPY_MODEL_e61e4cfc0cad45f3aecc5879397cd5a1"
      }
     },
     "2bf5b5cd49b74ffca8ad4a4dd28361b6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3333822df7684333a5af249b32bb5ed8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d3dbd64a749940eba4712a7761403874",
        "IPY_MODEL_95da57245ee44fd3bae9311663a30817",
        "IPY_MODEL_d25fdc25b0e44be883cfd25c70da8b1a"
       ],
       "layout": "IPY_MODEL_a9d163a43dfb47ad8f96a929ac077f67"
      }
     },
     "36b1bef591b047c0a3717d51792a6e84": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "39ddcceb915f4a21837b9d15f232cbba": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": null
      }
     },
     "3ccaf469669b421e9245f514aef7a65f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3fa151611b0a4f61ab460d3237690f5a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4c37f309c235440286364c8ddcbf192c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4d6550e4bc3d4e9b9d242ae28c98975d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "518174e9fec945d087aeee7d46dcec61": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e4aa852297e34bfdba2d77786dc793b1",
       "placeholder": "​",
       "style": "IPY_MODEL_0f0649784c0b41a19ba6e6f1ae7c8aff",
       "value": "100%"
      }
     },
     "55f661f8cacc47b091b8bcebfb769ad9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5765320d93374ca2a80c40979b026165": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "60db209078094e85b911f8b63a2318e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "78d3b7d01a85424f95bce2db801b5f06": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_518174e9fec945d087aeee7d46dcec61",
        "IPY_MODEL_88fff8c722464809ae93f4e49a1d73d7",
        "IPY_MODEL_dbdda1219edf4b4eae31324b991b7f6b"
       ],
       "layout": "IPY_MODEL_e788b859d4ac4909a0f3cce7151001d4"
      }
     },
     "812d5e254cc141a1b7617beb97d115ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "849ce00236fb4fdfb2884b649651f426": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "88fff8c722464809ae93f4e49a1d73d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_55f661f8cacc47b091b8bcebfb769ad9",
       "max": 3052.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2580cd7700fb4364b7f73e5a69c858ac",
       "value": 3052.0
      }
     },
     "8a33fb6441a34e87a0499f8db6dcb00c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_849ce00236fb4fdfb2884b649651f426",
       "placeholder": "​",
       "style": "IPY_MODEL_e481c5239a88431e9c504f236ffd858b",
       "value": " 99%"
      }
     },
     "8eff4538bc544998ab2f6df56fac7b1a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3ccaf469669b421e9245f514aef7a65f",
       "placeholder": "​",
       "style": "IPY_MODEL_1838dac72efe42dfaf3d456c584e0e55",
       "value": "100%"
      }
     },
     "95da57245ee44fd3bae9311663a30817": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_efb4f39f3e5149d8a2014fb82c697a8d",
       "max": 1802.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2198aeee23d54d58af916e6225c1d08f",
       "value": 1802.0
      }
     },
     "95df790ef56940ec945a75205678d2dc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9ddc6d1ee3d74a3a9b0264668e79c910": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a9d163a43dfb47ad8f96a929ac077f67": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a9f18f06ec0f4050b432a47fd196e4ee": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "acf0147cccf944d9900092d00a9e0cdb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9ddc6d1ee3d74a3a9b0264668e79c910",
       "placeholder": "​",
       "style": "IPY_MODEL_3fa151611b0a4f61ab460d3237690f5a",
       "value": "100%"
      }
     },
     "ae34df07647a430b943671c552d73b7a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b8e8dca9ec5044508b26dc192c4f8508": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b9ca6b22e42d4d9ebf6069edafbf301c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "bed4ba35346448b0b97d2e03654f39dc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c8c242d755894f9283b1cd77ded43359": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cac38a29db1e42ba8a362d118d913bac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8a33fb6441a34e87a0499f8db6dcb00c",
        "IPY_MODEL_0d8ba9c424d140b39162ddbbfec88e3b",
        "IPY_MODEL_edf08d7aacc147bf80316c8282ea4d34"
       ],
       "layout": "IPY_MODEL_39ddcceb915f4a21837b9d15f232cbba"
      }
     },
     "cadec0ff02ac492aa3deee42ff5ff33a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "cbb0566c533d46dd93368833a564804c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d25fdc25b0e44be883cfd25c70da8b1a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4c37f309c235440286364c8ddcbf192c",
       "placeholder": "​",
       "style": "IPY_MODEL_166d023939f342688d25044b6c69742c",
       "value": " 1802/1802 [52:01&lt;00:00,  1.52s/it]"
      }
     },
     "d3dbd64a749940eba4712a7761403874": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_111587e80bfe4036ac53917b5c9165c4",
       "placeholder": "​",
       "style": "IPY_MODEL_812d5e254cc141a1b7617beb97d115ad",
       "value": "100%"
      }
     },
     "d544d824f1af4365b74681416d6e0a3e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2bf5b5cd49b74ffca8ad4a4dd28361b6",
       "max": 85.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4d6550e4bc3d4e9b9d242ae28c98975d",
       "value": 85.0
      }
     },
     "dbdda1219edf4b4eae31324b991b7f6b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ae34df07647a430b943671c552d73b7a",
       "placeholder": "​",
       "style": "IPY_MODEL_cadec0ff02ac492aa3deee42ff5ff33a",
       "value": " 3052/3052 [1:28:28&lt;00:00,  1.54s/it]"
      }
     },
     "dc6086f98e014e65b0ff0dfe30ca0bf4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e481c5239a88431e9c504f236ffd858b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e4a81a3628e645f6854f4c9591d6a606": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_dc6086f98e014e65b0ff0dfe30ca0bf4",
       "placeholder": "​",
       "style": "IPY_MODEL_95df790ef56940ec945a75205678d2dc",
       "value": " 2/2 [02:51&lt;00:00, 91.82s/it]"
      }
     },
     "e4aa852297e34bfdba2d77786dc793b1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e61e4cfc0cad45f3aecc5879397cd5a1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": null
      }
     },
     "e788b859d4ac4909a0f3cce7151001d4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "edf08d7aacc147bf80316c8282ea4d34": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b8e8dca9ec5044508b26dc192c4f8508",
       "placeholder": "​",
       "style": "IPY_MODEL_36b1bef591b047c0a3717d51792a6e84",
       "value": " 168/170 [00:21&lt;00:00, 14.96it/s]"
      }
     },
     "efb4f39f3e5149d8a2014fb82c697a8d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f0616dd374dd4ddf83488c046958d696": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5765320d93374ca2a80c40979b026165",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_bed4ba35346448b0b97d2e03654f39dc",
       "value": 2.0
      }
     },
     "f388eb20501640c0a333120fc21ca707": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cbb0566c533d46dd93368833a564804c",
       "placeholder": "​",
       "style": "IPY_MODEL_60db209078094e85b911f8b63a2318e5",
       "value": " 85/85 [00:10&lt;00:00,  5.45it/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
